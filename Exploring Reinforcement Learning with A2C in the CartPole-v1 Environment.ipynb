{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WASANNADHIM/CS205_final_project/blob/master/Exploring%20Reinforcement%20Learning%20with%20A2C%20in%20the%20CartPole-v1%20Environment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJy9QoDC7XA7"
      },
      "source": [
        "# RL Baselines3 Zoo: Training in Colab\n",
        "\n",
        "> Indented block\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Github Repo: [https://github.com/DLR-RM/rl-baselines3-zoo](https://github.com/DLR-RM/rl-baselines3-zoo)\n",
        "\n",
        "Stable-Baselines3 Repo: [https://github.com/DLR-RM/rl-baselines3-zoo](https://github.com/DLR-RM/stable-baselines3)\n",
        "\n",
        "\n",
        "# Install Dependencies\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3enqEtbqSbkr",
        "outputId": "b779da3e-8fad-4e33-933a-bfcbdf405906"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "                <script type=\"application/javascript\" id=\"jupyter_black\">\n",
              "                (function() {\n",
              "                    if (window.IPython === undefined) {\n",
              "                        return\n",
              "                    }\n",
              "                    var msg = \"WARNING: it looks like you might have loaded \" +\n",
              "                        \"jupyter_black in a non-lab notebook with \" +\n",
              "                        \"`is_lab=True`. Please double check, and if \" +\n",
              "                        \"loading with `%load_ext` please review the README!\"\n",
              "                    console.log(msg)\n",
              "                    alert(msg)\n",
              "                })()\n",
              "                </script>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# for autoformatting\n",
        "# %load_ext jupyter_black"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXVDDlTn02M9",
        "outputId": "ab17d7ff-4fc8-470a-d91e-c439e679098c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "\r0% [Waiting for headers] [1 InRelease 0 B/110 kB 0%] [Connected to cloud.r-project.org (65.9.86.109)\r                                                                                                    \rHit:2 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\r0% [1 InRelease 110 kB/110 kB 100%] [Connected to cloud.r-project.org (65.9.86.109)] [Connected to p\r                                                                                                    \rGet:3 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "\r                                                                                                    \rHit:4 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "\r0% [Connected to cloud.r-project.org (65.9.86.109)] [Connected to ppa.launchpadcontent.net (185.125.\r                                                                                                    \rGet:5 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "\r                                                                                                    \r0% [5 InRelease 0 B/3,626 B 0%] [Waiting for headers] [Waiting for headers]\r                                                                           \r0% [Waiting for headers] [Waiting for headers]\r                                              \rGet:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "\r                                              \r0% [Waiting for headers]\r                        \rGet:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease [18.1 kB]\n",
            "\r0% [7 InRelease 16.0 kB/18.1 kB 89%]\r                                    \r0% [Waiting for headers]\r                        \rGet:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\n",
            "\r0% [Waiting for headers]\r                        \rHit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,322 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [50.4 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [1,649 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,624 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,346 kB]\n",
            "Get:16 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [664 kB]\n",
            "Get:17 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy/main Sources [2,263 kB]\n",
            "Get:18 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy/main amd64 Packages [1,161 kB]\n",
            "Get:19 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [28.2 kB]\n",
            "Fetched 10.4 MB in 2s (4,210 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "cmake is already the newest version (3.22.1-1ubuntu1.22.04.1).\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "The following additional packages will be installed:\n",
            "  freeglut3 libegl-dev libfontenc1 libgl-dev libgl1-mesa-dev libgles-dev libgles1 libglu1-mesa\n",
            "  libglu1-mesa-dev libglvnd-core-dev libglvnd-dev libglx-dev libice-dev libopengl-dev libsm-dev\n",
            "  libxfont2 libxkbfile1 libxt-dev swig4.0 x11-xkb-utils xfonts-base xfonts-encodings xfonts-utils\n",
            "  xserver-common\n",
            "Suggested packages:\n",
            "  libice-doc libsm-doc libxt-doc swig-doc swig-examples swig4.0-examples swig4.0-doc\n",
            "The following NEW packages will be installed:\n",
            "  freeglut3 freeglut3-dev libegl-dev libfontenc1 libgl-dev libgl1-mesa-dev libgles-dev libgles1\n",
            "  libglu1-mesa libglu1-mesa-dev libglvnd-core-dev libglvnd-dev libglx-dev libice-dev libopengl-dev\n",
            "  libsm-dev libxfont2 libxkbfile1 libxt-dev swig swig4.0 x11-xkb-utils xfonts-base xfonts-encodings\n",
            "  xfonts-utils xserver-common xvfb\n",
            "0 upgraded, 27 newly installed, 0 to remove and 40 not upgraded.\n",
            "Need to get 10.2 MB of archives.\n",
            "After this operation, 24.2 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 freeglut3 amd64 2.8.1-6 [74.0 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglx-dev amd64 1.4.0-1 [14.1 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgl-dev amd64 1.4.0-1 [101 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglvnd-core-dev amd64 1.4.0-1 [12.7 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 libegl-dev amd64 1.4.0-1 [18.0 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgles1 amd64 1.4.0-1 [11.5 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgles-dev amd64 1.4.0-1 [49.4 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 libopengl-dev amd64 1.4.0-1 [3,400 B]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglvnd-dev amd64 1.4.0-1 [3,162 B]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgl1-mesa-dev amd64 23.0.4-0ubuntu1~22.04.1 [6,510 B]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglu1-mesa amd64 9.0.2-1 [145 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglu1-mesa-dev amd64 9.0.2-1 [231 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy/main amd64 libice-dev amd64 2:1.0.10-1build2 [51.4 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsm-dev amd64 2:1.2.3-1build2 [18.1 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxt-dev amd64 1:1.2.1-1 [396 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy/universe amd64 freeglut3-dev amd64 2.8.1-6 [126 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfontenc1 amd64 1:1.1.4-1build3 [14.7 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxfont2 amd64 1:2.0.5-1build1 [94.5 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxkbfile1 amd64 1:1.1.0-1build3 [71.8 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy/universe amd64 swig4.0 amd64 4.0.2-1ubuntu1 [1,110 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy/universe amd64 swig all 4.0.2-1ubuntu1 [5,632 B]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu jammy/main amd64 x11-xkb-utils amd64 7.7+5build4 [172 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-encodings all 1:1.0.5-0ubuntu2 [578 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-utils amd64 1:7.7+6build2 [94.6 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-base all 1:1.0.5 [5,896 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 xserver-common all 2:21.1.4-2ubuntu1.7~22.04.7 [28.6 kB]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 xvfb amd64 2:21.1.4-2ubuntu1.7~22.04.7 [865 kB]\n",
            "Fetched 10.2 MB in 1s (15.7 MB/s)\n",
            "Selecting previously unselected package freeglut3:amd64.\n",
            "(Reading database ... 121658 files and directories currently installed.)\n",
            "Preparing to unpack .../00-freeglut3_2.8.1-6_amd64.deb ...\n",
            "Unpacking freeglut3:amd64 (2.8.1-6) ...\n",
            "Selecting previously unselected package libglx-dev:amd64.\n",
            "Preparing to unpack .../01-libglx-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libglx-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libgl-dev:amd64.\n",
            "Preparing to unpack .../02-libgl-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libgl-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libglvnd-core-dev:amd64.\n",
            "Preparing to unpack .../03-libglvnd-core-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libglvnd-core-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libegl-dev:amd64.\n",
            "Preparing to unpack .../04-libegl-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libegl-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libgles1:amd64.\n",
            "Preparing to unpack .../05-libgles1_1.4.0-1_amd64.deb ...\n",
            "Unpacking libgles1:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libgles-dev:amd64.\n",
            "Preparing to unpack .../06-libgles-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libgles-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libopengl-dev:amd64.\n",
            "Preparing to unpack .../07-libopengl-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libopengl-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libglvnd-dev:amd64.\n",
            "Preparing to unpack .../08-libglvnd-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libglvnd-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libgl1-mesa-dev:amd64.\n",
            "Preparing to unpack .../09-libgl1-mesa-dev_23.0.4-0ubuntu1~22.04.1_amd64.deb ...\n",
            "Unpacking libgl1-mesa-dev:amd64 (23.0.4-0ubuntu1~22.04.1) ...\n",
            "Selecting previously unselected package libglu1-mesa:amd64.\n",
            "Preparing to unpack .../10-libglu1-mesa_9.0.2-1_amd64.deb ...\n",
            "Unpacking libglu1-mesa:amd64 (9.0.2-1) ...\n",
            "Selecting previously unselected package libglu1-mesa-dev:amd64.\n",
            "Preparing to unpack .../11-libglu1-mesa-dev_9.0.2-1_amd64.deb ...\n",
            "Unpacking libglu1-mesa-dev:amd64 (9.0.2-1) ...\n",
            "Selecting previously unselected package libice-dev:amd64.\n",
            "Preparing to unpack .../12-libice-dev_2%3a1.0.10-1build2_amd64.deb ...\n",
            "Unpacking libice-dev:amd64 (2:1.0.10-1build2) ...\n",
            "Selecting previously unselected package libsm-dev:amd64.\n",
            "Preparing to unpack .../13-libsm-dev_2%3a1.2.3-1build2_amd64.deb ...\n",
            "Unpacking libsm-dev:amd64 (2:1.2.3-1build2) ...\n",
            "Selecting previously unselected package libxt-dev:amd64.\n",
            "Preparing to unpack .../14-libxt-dev_1%3a1.2.1-1_amd64.deb ...\n",
            "Unpacking libxt-dev:amd64 (1:1.2.1-1) ...\n",
            "Selecting previously unselected package freeglut3-dev:amd64.\n",
            "Preparing to unpack .../15-freeglut3-dev_2.8.1-6_amd64.deb ...\n",
            "Unpacking freeglut3-dev:amd64 (2.8.1-6) ...\n",
            "Selecting previously unselected package libfontenc1:amd64.\n",
            "Preparing to unpack .../16-libfontenc1_1%3a1.1.4-1build3_amd64.deb ...\n",
            "Unpacking libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Selecting previously unselected package libxfont2:amd64.\n",
            "Preparing to unpack .../17-libxfont2_1%3a2.0.5-1build1_amd64.deb ...\n",
            "Unpacking libxfont2:amd64 (1:2.0.5-1build1) ...\n",
            "Selecting previously unselected package libxkbfile1:amd64.\n",
            "Preparing to unpack .../18-libxkbfile1_1%3a1.1.0-1build3_amd64.deb ...\n",
            "Unpacking libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Selecting previously unselected package swig4.0.\n",
            "Preparing to unpack .../19-swig4.0_4.0.2-1ubuntu1_amd64.deb ...\n",
            "Unpacking swig4.0 (4.0.2-1ubuntu1) ...\n",
            "Selecting previously unselected package swig.\n",
            "Preparing to unpack .../20-swig_4.0.2-1ubuntu1_all.deb ...\n",
            "Unpacking swig (4.0.2-1ubuntu1) ...\n",
            "Selecting previously unselected package x11-xkb-utils.\n",
            "Preparing to unpack .../21-x11-xkb-utils_7.7+5build4_amd64.deb ...\n",
            "Unpacking x11-xkb-utils (7.7+5build4) ...\n",
            "Selecting previously unselected package xfonts-encodings.\n",
            "Preparing to unpack .../22-xfonts-encodings_1%3a1.0.5-0ubuntu2_all.deb ...\n",
            "Unpacking xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Selecting previously unselected package xfonts-utils.\n",
            "Preparing to unpack .../23-xfonts-utils_1%3a7.7+6build2_amd64.deb ...\n",
            "Unpacking xfonts-utils (1:7.7+6build2) ...\n",
            "Selecting previously unselected package xfonts-base.\n",
            "Preparing to unpack .../24-xfonts-base_1%3a1.0.5_all.deb ...\n",
            "Unpacking xfonts-base (1:1.0.5) ...\n",
            "Selecting previously unselected package xserver-common.\n",
            "Preparing to unpack .../25-xserver-common_2%3a21.1.4-2ubuntu1.7~22.04.7_all.deb ...\n",
            "Unpacking xserver-common (2:21.1.4-2ubuntu1.7~22.04.7) ...\n",
            "Selecting previously unselected package xvfb.\n",
            "Preparing to unpack .../26-xvfb_2%3a21.1.4-2ubuntu1.7~22.04.7_amd64.deb ...\n",
            "Unpacking xvfb (2:21.1.4-2ubuntu1.7~22.04.7) ...\n",
            "Setting up freeglut3:amd64 (2.8.1-6) ...\n",
            "Setting up libglvnd-core-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libice-dev:amd64 (2:1.0.10-1build2) ...\n",
            "Setting up libsm-dev:amd64 (2:1.2.3-1build2) ...\n",
            "Setting up libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Setting up libxt-dev:amd64 (1:1.2.1-1) ...\n",
            "Setting up libgles1:amd64 (1.4.0-1) ...\n",
            "Setting up xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Setting up libglx-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libglu1-mesa:amd64 (9.0.2-1) ...\n",
            "Setting up libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Setting up libopengl-dev:amd64 (1.4.0-1) ...\n",
            "Setting up swig4.0 (4.0.2-1ubuntu1) ...\n",
            "Setting up libxfont2:amd64 (1:2.0.5-1build1) ...\n",
            "Setting up libgl-dev:amd64 (1.4.0-1) ...\n",
            "Setting up swig (4.0.2-1ubuntu1) ...\n",
            "Setting up libegl-dev:amd64 (1.4.0-1) ...\n",
            "Setting up x11-xkb-utils (7.7+5build4) ...\n",
            "Setting up xfonts-utils (1:7.7+6build2) ...\n",
            "Setting up xfonts-base (1:1.0.5) ...\n",
            "Setting up libglu1-mesa-dev:amd64 (9.0.2-1) ...\n",
            "Setting up xserver-common (2:21.1.4-2ubuntu1.7~22.04.7) ...\n",
            "Setting up libgles-dev:amd64 (1.4.0-1) ...\n",
            "Setting up xvfb (2:21.1.4-2ubuntu1.7~22.04.7) ...\n",
            "Setting up libglvnd-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libgl1-mesa-dev:amd64 (23.0.4-0ubuntu1~22.04.1) ...\n",
            "Setting up freeglut3-dev:amd64 (2.8.1-6) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n"
          ]
        }
      ],
      "source": [
        "!apt-get update && apt-get install swig cmake ffmpeg freeglut3-dev xvfb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDjF3qRg7oGH"
      },
      "source": [
        "## Clone RL Baselines3 Zoo Repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCjGikdT1DFy",
        "outputId": "d5965c69-c9d7-4986-ff79-23cb841308a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'rl-baselines3-zoo'...\n",
            "remote: Enumerating objects: 5435, done.\u001b[K\n",
            "remote: Counting objects: 100% (280/280), done.\u001b[K\n",
            "remote: Compressing objects: 100% (179/179), done.\u001b[K\n",
            "remote: Total 5435 (delta 159), reused 164 (delta 86), pack-reused 5155\u001b[K\n",
            "Receiving objects: 100% (5435/5435), 3.86 MiB | 17.18 MiB/s, done.\n",
            "Resolving deltas: 100% (3579/3579), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/DLR-RM/rl-baselines3-zoo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "REMQlh-ezyVt",
        "outputId": "6f732958-ead3-4548-afe3-dd02bd4ab646"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/rl-baselines3-zoo\n"
          ]
        }
      ],
      "source": [
        "%cd /content/rl-baselines3-zoo/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tmD_QTBqTMb"
      },
      "source": [
        "### Install pip dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWIDzgJTqShY",
        "outputId": "80d53f7c-8c74-4912-f6ca-86521b407b2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gym==0.26.2 (from -r requirements.txt (line 1))\n",
            "  Downloading gym-0.26.2.tar.gz (721 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m721.7/721.7 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.3.0a1 (from -r requirements.txt (line 2))\n",
            "  Downloading stable_baselines3-2.3.0a1-py3-none-any.whl (181 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.7/181.7 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sb3-contrib<3.0,>=2.3.0a1 (from -r requirements.txt (line 3))\n",
            "  Downloading sb3_contrib-2.3.0a1-py3-none-any.whl (80 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.7/80.7 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting box2d-py==2.3.8 (from -r requirements.txt (line 4))\n",
            "  Downloading box2d-py-2.3.8.tar.gz (374 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.5/374.5 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pybullet (from -r requirements.txt (line 5))\n",
            "  Downloading pybullet-3.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (103.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.2/103.2 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pybullet_envs_gymnasium>=0.4.0 (from -r requirements.txt (line 6))\n",
            "  Downloading pybullet_envs_gymnasium-0.4.0-py3-none-any.whl (22 kB)\n",
            "Collecting optuna~=3.0 (from -r requirements.txt (line 9))\n",
            "  Downloading optuna-3.5.0-py3-none-any.whl (413 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m413.4/413.4 kB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (6.0.1)\n",
            "Requirement already satisfied: cloudpickle>=2.2.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (2.2.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (5.15.0)\n",
            "Collecting rliable>=1.0.5 (from -r requirements.txt (line 15))\n",
            "  Downloading rliable-1.0.8-py3-none-any.whl (19 kB)\n",
            "Collecting wandb (from -r requirements.txt (line 16))\n",
            "  Downloading wandb-0.16.2-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m87.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface_sb3<4.0,>=3.0 (from -r requirements.txt (line 17))\n",
            "  Downloading huggingface_sb3-3.0-py3-none-any.whl (9.7 kB)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 18)) (0.13.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 19)) (4.66.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 20)) (13.7.0)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 21)) (1.0.3)\n",
            "Collecting ruff (from -r requirements.txt (line 22))\n",
            "  Downloading ruff-0.1.14-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m100.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym==0.26.2->-r requirements.txt (line 1)) (1.23.5)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym==0.26.2->-r requirements.txt (line 1)) (0.0.8)\n",
            "Collecting gymnasium<0.30,>=0.28.1 (from stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.3.0a1->-r requirements.txt (line 2))\n",
            "  Downloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.3.0a1->-r requirements.txt (line 2)) (2.1.0+cu121)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.3.0a1->-r requirements.txt (line 2)) (1.5.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.3.0a1->-r requirements.txt (line 2)) (3.7.1)\n",
            "Requirement already satisfied: sphinx<8,>=5 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.3.0a1->-r requirements.txt (line 2)) (5.0.2)\n",
            "Collecting sphinx-autobuild (from stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.3.0a1->-r requirements.txt (line 2))\n",
            "  Downloading sphinx_autobuild-2021.3.14-py3-none-any.whl (9.9 kB)\n",
            "Collecting sphinx-rtd-theme>=1.3.0 (from stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.3.0a1->-r requirements.txt (line 2))\n",
            "  Downloading sphinx_rtd_theme-2.0.0-py2.py3-none-any.whl (2.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m93.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sphinxcontrib.spelling (from stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.3.0a1->-r requirements.txt (line 2))\n",
            "  Downloading sphinxcontrib_spelling-8.0.0-py3-none-any.whl (16 kB)\n",
            "Collecting sphinx-copybutton (from stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.3.0a1->-r requirements.txt (line 2))\n",
            "  Downloading sphinx_copybutton-0.5.2-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.3.0a1->-r requirements.txt (line 2)) (7.4.4)\n",
            "Collecting pytest-cov (from stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.3.0a1->-r requirements.txt (line 2))\n",
            "  Downloading pytest_cov-4.1.0-py3-none-any.whl (21 kB)\n",
            "Collecting pytest-env (from stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.3.0a1->-r requirements.txt (line 2))\n",
            "  Downloading pytest_env-1.1.3-py3-none-any.whl (6.2 kB)\n",
            "Collecting pytest-xdist (from stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.3.0a1->-r requirements.txt (line 2))\n",
            "  Downloading pytest_xdist-3.5.0-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mypy (from stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.3.0a1->-r requirements.txt (line 2))\n",
            "  Downloading mypy-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.5/12.5 MB\u001b[0m \u001b[31m59.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting black<24,>=23.9.1 (from stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.3.0a1->-r requirements.txt (line 2))\n",
            "  Downloading black-23.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m78.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.3.0a1->-r requirements.txt (line 2)) (4.8.0.76)\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.3.0a1->-r requirements.txt (line 2)) (2.5.2)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.3.0a1->-r requirements.txt (line 2)) (2.15.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.3.0a1->-r requirements.txt (line 2)) (5.9.5)\n",
            "Collecting shimmy[atari]~=1.3.0 (from stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.3.0a1->-r requirements.txt (line 2))\n",
            "  Downloading Shimmy-1.3.0-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.3.0a1->-r requirements.txt (line 2)) (9.4.0)\n",
            "Collecting alembic>=1.5.0 (from optuna~=3.0->-r requirements.txt (line 9))\n",
            "  Downloading alembic-1.13.1-py3-none-any.whl (233 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorlog (from optuna~=3.0->-r requirements.txt (line 9))\n",
            "  Downloading colorlog-6.8.0-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna~=3.0->-r requirements.txt (line 9)) (23.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna~=3.0->-r requirements.txt (line 9)) (2.0.24)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->-r requirements.txt (line 12)) (8.2.3)\n",
            "Collecting arch==5.3.0 (from rliable>=1.0.5->-r requirements.txt (line 15))\n",
            "  Downloading arch-5.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (905 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m905.4/905.4 kB\u001b[0m \u001b[31m69.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from rliable>=1.0.5->-r requirements.txt (line 15)) (1.11.4)\n",
            "Requirement already satisfied: absl-py>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from rliable>=1.0.5->-r requirements.txt (line 15)) (1.4.0)\n",
            "Requirement already satisfied: statsmodels>=0.11 in /usr/local/lib/python3.10/dist-packages (from arch==5.3.0->rliable>=1.0.5->-r requirements.txt (line 15)) (0.14.1)\n",
            "Collecting property-cached>=1.6.4 (from arch==5.3.0->rliable>=1.0.5->-r requirements.txt (line 15))\n",
            "  Downloading property_cached-1.6.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 16)) (8.1.7)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb->-r requirements.txt (line 16))\n",
            "  Downloading GitPython-3.1.41-py3-none-any.whl (196 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.4/196.4 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 16)) (2.31.0)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb->-r requirements.txt (line 16))\n",
            "  Downloading sentry_sdk-1.39.2-py2.py3-none-any.whl (254 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.1/254.1 kB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb->-r requirements.txt (line 16))\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting setproctitle (from wandb->-r requirements.txt (line 16))\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 16)) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 16)) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 16)) (3.20.3)\n",
            "Requirement already satisfied: huggingface-hub~=0.8 in /usr/local/lib/python3.10/dist-packages (from huggingface_sb3<4.0,>=3.0->-r requirements.txt (line 17)) (0.20.3)\n",
            "Requirement already satisfied: wasabi in /usr/local/lib/python3.10/dist-packages (from huggingface_sb3<4.0,>=3.0->-r requirements.txt (line 17)) (1.1.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->-r requirements.txt (line 20)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->-r requirements.txt (line 20)) (2.16.1)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy->-r requirements.txt (line 21)) (4.4.2)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy->-r requirements.txt (line 21)) (0.1.10)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy->-r requirements.txt (line 21)) (2.31.6)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy->-r requirements.txt (line 21)) (0.4.9)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna~=3.0->-r requirements.txt (line 9))\n",
            "  Downloading Mako-1.3.1-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna~=3.0->-r requirements.txt (line 9)) (4.5.0)\n",
            "Collecting mypy-extensions>=0.4.3 (from black<24,>=23.9.1->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.3.0a1->-r requirements.txt (line 2))\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Collecting pathspec>=0.9.0 (from black<24,>=23.9.1->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.3.0a1->-r requirements.txt (line 2))\n",
            "  Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.10/dist-packages (from black<24,>=23.9.1->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.3.0a1->-r requirements.txt (line 2)) (4.1.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from black<24,>=23.9.1->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.3.0a1->-r requirements.txt (line 2)) (2.0.1)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb->-r requirements.txt (line 16)) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 16))\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting farama-notifications>=0.0.1 (from gymnasium<0.30,>=0.28.1->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.3.0a1->-r requirements.txt (line 2))\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub~=0.8->huggingface_sb3<4.0,>=3.0->-r requirements.txt (line 17)) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub~=0.8->huggingface_sb3<4.0,>=3.0->-r requirements.txt (line 17)) (2023.6.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->-r requirements.txt (line 20)) (0.1.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.3.0a1->-r requirements.txt (line 2)) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.3.0a1->-r requirements.txt (line 2)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.3.0a1->-r requirements.txt (line 2)) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.3.0a1->-r requirements.txt (line 2)) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.3.0a1->-r requirements.txt (line 2)) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.3.0a1->-r requirements.txt (line 2)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.3.0a1->-r requirements.txt (line 2)) (2023.3.post1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 16)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 16)) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 16)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 16)) (2023.11.17)\n",
            "Collecting ale-py~=0.8.1 (from shimmy[atari]~=1.3.0->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.3.0a1->-r requirements.txt (line 2))\n",
            "  Downloading ale_py-0.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m70.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sphinxcontrib-applehelp in /usr/local/lib/python3.10/dist-packages (from sphinx<8,>=5->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.3.0a1->-r requirements.txt (line 2)) (1.0.8)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp in /usr/local/lib/python3.10/dist-packages (from sphinx<8,>=5->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.3.0a1->-r requirements.txt (line 2)) (1.0.6)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath in /usr/local/lib/python3.10/dist-packages (from sphinx<8,>=5->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.3.0a1->-r requirements.txt (line 2)) (1.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from sphinx<8,>=5->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.3.0a1->-r requirements.txt (line 2)) (2.0.5)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from sphinx<8,>=5->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.3.0a1->-r requirements.txt (line 2)) (1.1.10)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp in /usr/local/lib/python3.10/dist-packages (from sphinx<8,>=5->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.3.0a1->-r requirements.txt (line 2)) (1.0.7)\n",
            "Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.10/dist-packages (from sphinx<8,>=5->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.3.0a1->-r requirements.txt (line 2)) (3.1.3)\n",
            "Requirement already satisfied: docutils<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from sphinx<8,>=5->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.3.0a1->-r requirements.txt (line 2)) (0.18.1)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.10/dist-packages (from sphinx<8,>=5->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.3.0a1->-r requirements.txt (line 2)) (2.2.0)\n",
            "Requirement already satisfied: babel>=1.3 in /usr/local/lib/python3.10/dist-packages (from sphinx<8,>=5->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.3.0a1->-r requirements.txt (line 2)) (2.14.0)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.10/dist-packages (from sphinx<8,>=5->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.3.0a1->-r requirements.txt (line 2)) (0.7.16)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.10/dist-packages (from sphinx<8,>=5->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.3.0a1->-r requirements.txt (line 2)) (1.4.1)\n",
            "Collecting sphinxcontrib-jquery<5,>=4 (from sphinx-rtd-theme>=1.3.0->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.3.0a1->-r requirements.txt (line 2))\n",
            "  Downloading sphinxcontrib_jquery-4.1-py2.py3-none-any.whl (121 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.1/121.1 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna~=3.0->-r requirements.txt (line 9)) (3.0.3)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.3.0a1->-r requirements.txt (line 2)) (1.60.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.3.0a1->-r requirements.txt (line 2)) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.3.0a1->-r requirements.txt (line 2)) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.3.0a1->-r requirements.txt (line 2)) (3.5.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.3.0a1->-r requirements.txt (line 2)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.3.0a1->-r requirements.txt (line 2)) (3.0.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.3.0a1->-r requirements.txt (line 2)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.3.0a1->-r requirements.txt (line 2)) (3.2.1)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.3.0a1->-r requirements.txt (line 2)) (2.1.0)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.3.0a1->-r requirements.txt (line 2)) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.3.0a1->-r requirements.txt (line 2)) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.3.0a1->-r requirements.txt (line 2)) (1.2.0)\n",
            "Collecting coverage[toml]>=5.2.1 (from pytest-cov->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.3.0a1->-r requirements.txt (line 2))\n",
            "  Downloading coverage-7.4.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (233 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.2/233.2 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting execnet>=1.1 (from pytest-xdist->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.3.0a1->-r requirements.txt (line 2))\n",
            "  Downloading execnet-2.0.2-py3-none-any.whl (37 kB)\n",
            "Collecting livereload (from sphinx-autobuild->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.3.0a1->-r requirements.txt (line 2))\n",
            "  Downloading livereload-2.6.3-py2.py3-none-any.whl (24 kB)\n",
            "Collecting colorama (from sphinx-autobuild->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.3.0a1->-r requirements.txt (line 2))\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting PyEnchant>=3.1.1 (from sphinxcontrib.spelling->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.3.0a1->-r requirements.txt (line 2))\n",
            "  Downloading pyenchant-3.2.2-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.7/55.7 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from ale-py~=0.8.1->shimmy[atari]~=1.3.0->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.3.0a1->-r requirements.txt (line 2)) (6.1.1)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 16))\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.3.0a1->-r requirements.txt (line 2)) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.3.0a1->-r requirements.txt (line 2)) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.3.0a1->-r requirements.txt (line 2)) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard>=2.9.1->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.3.0a1->-r requirements.txt (line 2)) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=2.3->sphinx<8,>=5->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.3.0a1->-r requirements.txt (line 2)) (2.1.4)\n",
            "Requirement already satisfied: patsy>=0.5.4 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.11->arch==5.3.0->rliable>=1.0.5->-r requirements.txt (line 15)) (0.5.6)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.10/dist-packages (from livereload->sphinx-autobuild->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.3.0a1->-r requirements.txt (line 2)) (6.3.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.3.0a1->-r requirements.txt (line 2)) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.3.0a1->-r requirements.txt (line 2)) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard>=2.9.1->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.3.0a1->-r requirements.txt (line 2)) (3.2.2)\n",
            "Building wheels for collected packages: gym, box2d-py\n",
            "  Building wheel for gym (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.26.2-py3-none-any.whl size=827622 sha256=130a8f2b8ac5d1bf47e79a9cebe4e916faac533de38fe17421102d463747991e\n",
            "  Stored in directory: /root/.cache/pip/wheels/b9/22/6d/3e7b32d98451b4cd9d12417052affbeeeea012955d437da1da\n",
            "  Building wheel for box2d-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for box2d-py: filename=box2d_py-2.3.8-cp310-cp310-linux_x86_64.whl size=2349147 sha256=a61d1af8f7f50778ea0e501b07eb190949e7a081204c531bd4daefc2e32a3f7c\n",
            "  Stored in directory: /root/.cache/pip/wheels/47/01/d2/6a780da77ccb98b1d2facdd520a8d10838a03b590f6f8d50c0\n",
            "Successfully built gym box2d-py\n",
            "Installing collected packages: pybullet, farama-notifications, box2d-py, smmap, setproctitle, sentry-sdk, ruff, PyEnchant, property-cached, pathspec, mypy-extensions, Mako, livereload, gymnasium, gym, execnet, docker-pycreds, coverage, colorlog, colorama, ale-py, shimmy, pytest-xdist, pytest-env, pybullet_envs_gymnasium, mypy, gitdb, black, alembic, stable-baselines3, sphinxcontrib.spelling, sphinxcontrib-jquery, sphinx-copybutton, sphinx-autobuild, pytest-cov, optuna, huggingface_sb3, GitPython, wandb, sphinx-rtd-theme, sb3-contrib, arch, rliable\n",
            "  Attempting uninstall: gym\n",
            "    Found existing installation: gym 0.25.2\n",
            "    Uninstalling gym-0.25.2:\n",
            "      Successfully uninstalled gym-0.25.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dopamine-rl 4.0.6 requires gym<=0.25.2, but you have gym 0.26.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed GitPython-3.1.41 Mako-1.3.1 PyEnchant-3.2.2 ale-py-0.8.1 alembic-1.13.1 arch-5.3.0 black-23.12.1 box2d-py-2.3.8 colorama-0.4.6 colorlog-6.8.0 coverage-7.4.0 docker-pycreds-0.4.0 execnet-2.0.2 farama-notifications-0.0.4 gitdb-4.0.11 gym-0.26.2 gymnasium-0.29.1 huggingface_sb3-3.0 livereload-2.6.3 mypy-1.8.0 mypy-extensions-1.0.0 optuna-3.5.0 pathspec-0.12.1 property-cached-1.6.4 pybullet-3.2.6 pybullet_envs_gymnasium-0.4.0 pytest-cov-4.1.0 pytest-env-1.1.3 pytest-xdist-3.5.0 rliable-1.0.8 ruff-0.1.14 sb3-contrib-2.3.0a1 sentry-sdk-1.39.2 setproctitle-1.3.3 shimmy-1.3.0 smmap-5.0.1 sphinx-autobuild-2021.3.14 sphinx-copybutton-0.5.2 sphinx-rtd-theme-2.0.0 sphinxcontrib-jquery-4.1 sphinxcontrib.spelling-8.0.0 stable-baselines3-2.3.0a1 wandb-0.16.2\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gJ-pAbF7zRZ"
      },
      "source": [
        "## Train an RL Agent\n",
        "\n",
        "\n",
        "The train agent can be found in the `logs/` folder.\n",
        "\n",
        "Here we will train A2C on CartPole-v1 environment for 100 000 steps.\n",
        "\n",
        "\n",
        "To train it on Pong (Atari), you just have to pass `--env PongNoFrameskip-v4`\n",
        "\n",
        "Note: You need to update `hyperparams/algo.yml` to support new environments. You can access it in the side panel of Google Colab. (see https://stackoverflow.com/questions/46986398/import-data-into-google-colaboratory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bIR_N7R11XI",
        "outputId": "9d5c8906-1f68-4aed-9f62-1cc028a87e62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-01-24 19:27:35.977449: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-01-24 19:27:35.977509: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-01-24 19:27:35.978812: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-01-24 19:27:35.986093: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-01-24 19:27:37.099414: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "========== CartPole-v1 ==========\n",
            "Seed: 218708839\n",
            "Loading hyperparameters from: /content/rl-baselines3-zoo/hyperparams/a2c.yml\n",
            "Default hyperparameters for environment (ones being tuned will be overridden):\n",
            "OrderedDict([('ent_coef', 0.0),\n",
            "             ('n_envs', 8),\n",
            "             ('n_timesteps', 500000.0),\n",
            "             ('policy', 'MlpPolicy')])\n",
            "Using 8 environments\n",
            "Overwriting n_timesteps with n=100000\n",
            "Creating test environment\n",
            "Using cuda device\n",
            "Log path: logs/a2c/CartPole-v1_1\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 19.4     |\n",
            "|    ep_rew_mean        | 19.4     |\n",
            "| time/                 |          |\n",
            "|    fps                | 1272     |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 4000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.672   |\n",
            "|    explained_variance | 0.165    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 99       |\n",
            "|    policy_loss        | 0.456    |\n",
            "|    value_loss         | 19       |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 43.9     |\n",
            "|    ep_rew_mean        | 43.9     |\n",
            "| time/                 |          |\n",
            "|    fps                | 1855     |\n",
            "|    iterations         | 200      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 8000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.63    |\n",
            "|    explained_variance | 0.0916   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 199      |\n",
            "|    policy_loss        | 1.44     |\n",
            "|    value_loss         | 7.17     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 70       |\n",
            "|    ep_rew_mean        | 70       |\n",
            "| time/                 |          |\n",
            "|    fps                | 2191     |\n",
            "|    iterations         | 300      |\n",
            "|    time_elapsed       | 5        |\n",
            "|    total_timesteps    | 12000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.607   |\n",
            "|    explained_variance | -0.0209  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 299      |\n",
            "|    policy_loss        | 1.18     |\n",
            "|    value_loss         | 6.05     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 102      |\n",
            "|    ep_rew_mean        | 102      |\n",
            "| time/                 |          |\n",
            "|    fps                | 2400     |\n",
            "|    iterations         | 400      |\n",
            "|    time_elapsed       | 6        |\n",
            "|    total_timesteps    | 16000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.589   |\n",
            "|    explained_variance | 0.0799   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 399      |\n",
            "|    policy_loss        | 1.13     |\n",
            "|    value_loss         | 5.26     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 140      |\n",
            "|    ep_rew_mean        | 140      |\n",
            "| time/                 |          |\n",
            "|    fps                | 2526     |\n",
            "|    iterations         | 500      |\n",
            "|    time_elapsed       | 7        |\n",
            "|    total_timesteps    | 20000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.559   |\n",
            "|    explained_variance | 0.00363  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 499      |\n",
            "|    policy_loss        | 0.145    |\n",
            "|    value_loss         | 54.9     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 172      |\n",
            "|    ep_rew_mean        | 172      |\n",
            "| time/                 |          |\n",
            "|    fps                | 2631     |\n",
            "|    iterations         | 600      |\n",
            "|    time_elapsed       | 9        |\n",
            "|    total_timesteps    | 24000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.511   |\n",
            "|    explained_variance | -0.00246 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 599      |\n",
            "|    policy_loss        | 1.09     |\n",
            "|    value_loss         | 3.75     |\n",
            "------------------------------------\n",
            "Eval num_timesteps=25000, episode_reward=421.20 +/- 96.56\n",
            "Episode length: 421.20 +/- 96.56\n",
            "------------------------------------\n",
            "| eval/                 |          |\n",
            "|    mean_ep_length     | 421      |\n",
            "|    mean_reward        | 421      |\n",
            "| time/                 |          |\n",
            "|    total_timesteps    | 25000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.58    |\n",
            "|    explained_variance | 0.00195  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 624      |\n",
            "|    policy_loss        | 0.927    |\n",
            "|    value_loss         | 3.95     |\n",
            "------------------------------------\n",
            "New best mean reward!\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 205      |\n",
            "|    ep_rew_mean        | 205      |\n",
            "| time/                 |          |\n",
            "|    fps                | 2259     |\n",
            "|    iterations         | 700      |\n",
            "|    time_elapsed       | 12       |\n",
            "|    total_timesteps    | 28000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.512   |\n",
            "|    explained_variance | -0.00187 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 699      |\n",
            "|    policy_loss        | 0.767    |\n",
            "|    value_loss         | 3.54     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 240      |\n",
            "|    ep_rew_mean        | 240      |\n",
            "| time/                 |          |\n",
            "|    fps                | 2317     |\n",
            "|    iterations         | 800      |\n",
            "|    time_elapsed       | 13       |\n",
            "|    total_timesteps    | 32000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.557   |\n",
            "|    explained_variance | 0.000467 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 799      |\n",
            "|    policy_loss        | 0.626    |\n",
            "|    value_loss         | 3.06     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 256      |\n",
            "|    ep_rew_mean        | 256      |\n",
            "| time/                 |          |\n",
            "|    fps                | 2405     |\n",
            "|    iterations         | 900      |\n",
            "|    time_elapsed       | 14       |\n",
            "|    total_timesteps    | 36000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.547   |\n",
            "|    explained_variance | 0.000194 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 899      |\n",
            "|    policy_loss        | 0.579    |\n",
            "|    value_loss         | 2.68     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 286      |\n",
            "|    ep_rew_mean        | 286      |\n",
            "| time/                 |          |\n",
            "|    fps                | 2479     |\n",
            "|    iterations         | 1000     |\n",
            "|    time_elapsed       | 16       |\n",
            "|    total_timesteps    | 40000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.492   |\n",
            "|    explained_variance | 0.000678 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 999      |\n",
            "|    policy_loss        | 0.84     |\n",
            "|    value_loss         | 2.2      |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 308       |\n",
            "|    ep_rew_mean        | 308       |\n",
            "| time/                 |           |\n",
            "|    fps                | 2546      |\n",
            "|    iterations         | 1100      |\n",
            "|    time_elapsed       | 17        |\n",
            "|    total_timesteps    | 44000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.473    |\n",
            "|    explained_variance | -0.000493 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1099      |\n",
            "|    policy_loss        | 0.551     |\n",
            "|    value_loss         | 1.8       |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 325       |\n",
            "|    ep_rew_mean        | 325       |\n",
            "| time/                 |           |\n",
            "|    fps                | 2604      |\n",
            "|    iterations         | 1200      |\n",
            "|    time_elapsed       | 18        |\n",
            "|    total_timesteps    | 48000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.505    |\n",
            "|    explained_variance | -0.000115 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1199      |\n",
            "|    policy_loss        | 0.558     |\n",
            "|    value_loss         | 1.48      |\n",
            "-------------------------------------\n",
            "Eval num_timesteps=50000, episode_reward=271.20 +/- 117.73\n",
            "Episode length: 271.20 +/- 117.73\n",
            "------------------------------------\n",
            "| eval/                 |          |\n",
            "|    mean_ep_length     | 271      |\n",
            "|    mean_reward        | 271      |\n",
            "| time/                 |          |\n",
            "|    total_timesteps    | 50000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.493   |\n",
            "|    explained_variance | 0.000128 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1249     |\n",
            "|    policy_loss        | 0.607    |\n",
            "|    value_loss         | 1.33     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 340       |\n",
            "|    ep_rew_mean        | 340       |\n",
            "| time/                 |           |\n",
            "|    fps                | 2521      |\n",
            "|    iterations         | 1300      |\n",
            "|    time_elapsed       | 20        |\n",
            "|    total_timesteps    | 52000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.491    |\n",
            "|    explained_variance | -0.000219 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1299      |\n",
            "|    policy_loss        | 0.459     |\n",
            "|    value_loss         | 1.22      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 342       |\n",
            "|    ep_rew_mean        | 342       |\n",
            "| time/                 |           |\n",
            "|    fps                | 2567      |\n",
            "|    iterations         | 1400      |\n",
            "|    time_elapsed       | 21        |\n",
            "|    total_timesteps    | 56000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.556    |\n",
            "|    explained_variance | -8.98e-05 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1399      |\n",
            "|    policy_loss        | 0.477     |\n",
            "|    value_loss         | 0.959     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 326       |\n",
            "|    ep_rew_mean        | 326       |\n",
            "| time/                 |           |\n",
            "|    fps                | 2594      |\n",
            "|    iterations         | 1500      |\n",
            "|    time_elapsed       | 23        |\n",
            "|    total_timesteps    | 60000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.512    |\n",
            "|    explained_variance | -8.61e-05 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1499      |\n",
            "|    policy_loss        | 0.436     |\n",
            "|    value_loss         | 0.748     |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 301      |\n",
            "|    ep_rew_mean        | 301      |\n",
            "| time/                 |          |\n",
            "|    fps                | 2588     |\n",
            "|    iterations         | 1600     |\n",
            "|    time_elapsed       | 24       |\n",
            "|    total_timesteps    | 64000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.477   |\n",
            "|    explained_variance | 0.101    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1599     |\n",
            "|    policy_loss        | 0.393    |\n",
            "|    value_loss         | 0.574    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 207      |\n",
            "|    ep_rew_mean        | 207      |\n",
            "| time/                 |          |\n",
            "|    fps                | 2618     |\n",
            "|    iterations         | 1700     |\n",
            "|    time_elapsed       | 25       |\n",
            "|    total_timesteps    | 68000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.481   |\n",
            "|    explained_variance | 0.819    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1699     |\n",
            "|    policy_loss        | -1.53    |\n",
            "|    value_loss         | 31.2     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 81.7     |\n",
            "|    ep_rew_mean        | 81.7     |\n",
            "| time/                 |          |\n",
            "|    fps                | 2648     |\n",
            "|    iterations         | 1800     |\n",
            "|    time_elapsed       | 27       |\n",
            "|    total_timesteps    | 72000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.525   |\n",
            "|    explained_variance | 0.973    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1799     |\n",
            "|    policy_loss        | -1.59    |\n",
            "|    value_loss         | 71.2     |\n",
            "------------------------------------\n",
            "Eval num_timesteps=75000, episode_reward=41.20 +/- 5.31\n",
            "Episode length: 41.20 +/- 5.31\n",
            "------------------------------------\n",
            "| eval/                 |          |\n",
            "|    mean_ep_length     | 41.2     |\n",
            "|    mean_reward        | 41.2     |\n",
            "| time/                 |          |\n",
            "|    total_timesteps    | 75000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.517   |\n",
            "|    explained_variance | 0.756    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1874     |\n",
            "|    policy_loss        | 1.29     |\n",
            "|    value_loss         | 180      |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 41.1     |\n",
            "|    ep_rew_mean        | 41.1     |\n",
            "| time/                 |          |\n",
            "|    fps                | 2663     |\n",
            "|    iterations         | 1900     |\n",
            "|    time_elapsed       | 28       |\n",
            "|    total_timesteps    | 76000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.479   |\n",
            "|    explained_variance | 0.889    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1899     |\n",
            "|    policy_loss        | 2.25     |\n",
            "|    value_loss         | 89.8     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 54.9     |\n",
            "|    ep_rew_mean        | 54.9     |\n",
            "| time/                 |          |\n",
            "|    fps                | 2694     |\n",
            "|    iterations         | 2000     |\n",
            "|    time_elapsed       | 29       |\n",
            "|    total_timesteps    | 80000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.519   |\n",
            "|    explained_variance | 0.997    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1999     |\n",
            "|    policy_loss        | 0.618    |\n",
            "|    value_loss         | 5.23     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 80.2     |\n",
            "|    ep_rew_mean        | 80.2     |\n",
            "| time/                 |          |\n",
            "|    fps                | 2722     |\n",
            "|    iterations         | 2100     |\n",
            "|    time_elapsed       | 30       |\n",
            "|    total_timesteps    | 84000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.523   |\n",
            "|    explained_variance | 0.963    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2099     |\n",
            "|    policy_loss        | 0.287    |\n",
            "|    value_loss         | 0.71     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 88.5     |\n",
            "|    ep_rew_mean        | 88.5     |\n",
            "| time/                 |          |\n",
            "|    fps                | 2749     |\n",
            "|    iterations         | 2200     |\n",
            "|    time_elapsed       | 32       |\n",
            "|    total_timesteps    | 88000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.492   |\n",
            "|    explained_variance | 0.951    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2199     |\n",
            "|    policy_loss        | -0.557   |\n",
            "|    value_loss         | 20.3     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 92.3     |\n",
            "|    ep_rew_mean        | 92.3     |\n",
            "| time/                 |          |\n",
            "|    fps                | 2773     |\n",
            "|    iterations         | 2300     |\n",
            "|    time_elapsed       | 33       |\n",
            "|    total_timesteps    | 92000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.503   |\n",
            "|    explained_variance | 0.919    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2299     |\n",
            "|    policy_loss        | 0.494    |\n",
            "|    value_loss         | 2.29     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 118      |\n",
            "|    ep_rew_mean        | 118      |\n",
            "| time/                 |          |\n",
            "|    fps                | 2796     |\n",
            "|    iterations         | 2400     |\n",
            "|    time_elapsed       | 34       |\n",
            "|    total_timesteps    | 96000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.512   |\n",
            "|    explained_variance | -0.379   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2399     |\n",
            "|    policy_loss        | 0.306    |\n",
            "|    value_loss         | 0.456    |\n",
            "------------------------------------\n",
            "Eval num_timesteps=100000, episode_reward=500.00 +/- 0.00\n",
            "Episode length: 500.00 +/- 0.00\n",
            "------------------------------------\n",
            "| eval/                 |          |\n",
            "|    mean_ep_length     | 500      |\n",
            "|    mean_reward        | 500      |\n",
            "| time/                 |          |\n",
            "|    total_timesteps    | 100000   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.527   |\n",
            "|    explained_variance | 0.0893   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2499     |\n",
            "|    policy_loss        | 0.17     |\n",
            "|    value_loss         | 0.136    |\n",
            "------------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 149      |\n",
            "|    ep_rew_mean     | 149      |\n",
            "| time/              |          |\n",
            "|    fps             | 2636     |\n",
            "|    iterations      | 2500     |\n",
            "|    time_elapsed    | 37       |\n",
            "|    total_timesteps | 100000   |\n",
            "---------------------------------\n",
            "Saving to logs/a2c/CartPole-v1_1\n"
          ]
        }
      ],
      "source": [
        "!python -m rl_zoo3.train --algo a2c --env CartPole-v1 --n-timesteps 100000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fHBq73665yD"
      },
      "source": [
        "#### Evaluate trained agent\n",
        "\n",
        "\n",
        "You can remove the `--folder logs/` to evaluate pretrained agent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bw8YuEgU6bT3",
        "outputId": "8ec0eb73-5968-4e3b-84df-3913ddc61610"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-01-24 19:28:28.414692: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-01-24 19:28:28.414738: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-01-24 19:28:28.416670: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-01-24 19:28:28.427841: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-01-24 19:28:30.120742: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Loading latest experiment, id=1\n",
            "Loading logs/a2c/CartPole-v1_1/CartPole-v1.zip\n",
            "Episode Reward: 500.00\n",
            "Episode Length 500\n",
            "Episode Reward: 500.00\n",
            "Episode Length 500\n",
            "Episode Reward: 500.00\n",
            "Episode Length 500\n",
            "Episode Reward: 500.00\n",
            "Episode Length 500\n",
            "Episode Reward: 500.00\n",
            "Episode Length 500\n",
            "Episode Reward: 500.00\n",
            "Episode Length 500\n",
            "Episode Reward: 500.00\n",
            "Episode Length 500\n",
            "Episode Reward: 500.00\n",
            "Episode Length 500\n",
            "Episode Reward: 500.00\n",
            "Episode Length 500\n",
            "Episode Reward: 500.00\n",
            "Episode Length 500\n",
            "10 Episodes\n",
            "Mean reward: 500.00 +/- 0.00\n",
            "Mean episode length: 500.00 +/- 0.00\n"
          ]
        }
      ],
      "source": [
        "!python -m rl_zoo3.enjoy --algo a2c --env CartPole-v1 --no-render --n-timesteps 5000 --folder logs/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5Il2J0VHPLC"
      },
      "source": [
        "#### Tune Hyperparameters\n",
        "\n",
        "We use [Optuna](https://optuna.org/) for optimizing the hyperparameters.\n",
        "\n",
        "Tune the hyperparameters for PPO, using a tpe sampler and median pruner, 2 parallels jobs,\n",
        "with a budget of 1000 trials and a maximum of 50000 steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2sC22eGHTH-",
        "outputId": "0ace0b09-3b1e-4024-8d9d-f9eca9817074"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-01-24 19:35:01.161813: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-01-24 19:35:01.161866: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-01-24 19:35:01.163195: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-01-24 19:35:01.170218: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-01-24 19:35:02.286894: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "========== MountainCar-v0 ==========\n",
            "Seed: 3160034198\n",
            "Loading hyperparameters from: /content/rl-baselines3-zoo/hyperparams/ppo.yml\n",
            "Default hyperparameters for environment (ones being tuned will be overridden):\n",
            "OrderedDict([('ent_coef', 0.0),\n",
            "             ('gae_lambda', 0.98),\n",
            "             ('gamma', 0.99),\n",
            "             ('n_envs', 16),\n",
            "             ('n_epochs', 4),\n",
            "             ('n_steps', 16),\n",
            "             ('n_timesteps', 1000000.0),\n",
            "             ('normalize', True),\n",
            "             ('policy', 'MlpPolicy')])\n",
            "Using 16 environments\n",
            "Overwriting n_timesteps with n=500\n",
            "Doing 1 intermediate evaluations for pruning based on the number of timesteps. (1 evaluation every 100k timesteps)\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Optimizing hyperparameters\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/samplers/_tpe/sampler.py:319: ExperimentalWarning: ``multivariate`` option is an experimental feature. The interface can change in the future.\n",
            "  warnings.warn(\n",
            "Sampler: tpe - Pruner: median\n",
            "\u001b[32m[I 2024-01-24 19:35:04,911]\u001b[0m A new study created in memory with name: no-name-67e5cd97-974b-4663-bc11-b02dd7400e39\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 19:36:20,116]\u001b[0m Trial 1 finished with value: -200.0 and parameters: {'batch_size': 32, 'n_steps': 512, 'gamma': 0.95, 'learning_rate': 0.00024187039525146325, 'ent_coef': 0.003002689028344893, 'clip_range': 0.4, 'n_epochs': 10, 'gae_lambda': 0.99, 'max_grad_norm': 2, 'vf_coef': 0.08561890081788603, 'net_arch': 'medium', 'activation_fn': 'tanh'}. Best is trial 1 with value: -200.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 19:36:41,021]\u001b[0m Trial 2 finished with value: -200.0 and parameters: {'batch_size': 512, 'n_steps': 256, 'gamma': 0.98, 'learning_rate': 0.0007768683620569337, 'ent_coef': 0.029902680295692576, 'clip_range': 0.3, 'n_epochs': 10, 'gae_lambda': 0.95, 'max_grad_norm': 5, 'vf_coef': 0.520844823720086, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 1 with value: -200.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 19:36:59,955]\u001b[0m Trial 3 finished with value: -200.0 and parameters: {'batch_size': 16, 'n_steps': 8, 'gamma': 0.98, 'learning_rate': 0.0007249515513795575, 'ent_coef': 0.0006304383836627345, 'clip_range': 0.2, 'n_epochs': 20, 'gae_lambda': 0.8, 'max_grad_norm': 0.6, 'vf_coef': 0.7283096715060637, 'net_arch': 'medium', 'activation_fn': 'relu'}. Best is trial 1 with value: -200.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 19:37:02,779]\u001b[0m Trial 4 finished with value: -200.0 and parameters: {'batch_size': 32, 'n_steps': 32, 'gamma': 0.98, 'learning_rate': 0.0005070774180707963, 'ent_coef': 1.1542117992847803e-06, 'clip_range': 0.1, 'n_epochs': 1, 'gae_lambda': 0.99, 'max_grad_norm': 5, 'vf_coef': 0.25164039273934435, 'net_arch': 'medium', 'activation_fn': 'relu'}. Best is trial 1 with value: -200.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 19:37:46,478]\u001b[0m Trial 5 finished with value: -200.0 and parameters: {'batch_size': 32, 'n_steps': 512, 'gamma': 0.99, 'learning_rate': 0.00010851447696597817, 'ent_coef': 1.982091120129414e-05, 'clip_range': 0.1, 'n_epochs': 5, 'gae_lambda': 0.98, 'max_grad_norm': 0.5, 'vf_coef': 0.8257192448051561, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 1 with value: -200.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 19:37:51,232]\u001b[0m Trial 6 finished with value: -200.0 and parameters: {'batch_size': 32, 'n_steps': 32, 'gamma': 0.95, 'learning_rate': 0.5510022669251518, 'ent_coef': 0.010936607416301761, 'clip_range': 0.4, 'n_epochs': 20, 'gae_lambda': 0.92, 'max_grad_norm': 5, 'vf_coef': 0.055082514897587975, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 1 with value: -200.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 19:37:57,708]\u001b[0m Trial 7 finished with value: -200.0 and parameters: {'batch_size': 8, 'n_steps': 32, 'gamma': 0.9999, 'learning_rate': 0.00019008530447368676, 'ent_coef': 8.691778774714257e-08, 'clip_range': 0.4, 'n_epochs': 10, 'gae_lambda': 0.8, 'max_grad_norm': 0.6, 'vf_coef': 0.4118494246230676, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 1 with value: -200.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 19:38:01,498]\u001b[0m Trial 8 finished with value: -187.4 and parameters: {'batch_size': 16, 'n_steps': 32, 'gamma': 0.99, 'learning_rate': 7.207744086883807e-05, 'ent_coef': 0.00020781609974501354, 'clip_range': 0.3, 'n_epochs': 5, 'gae_lambda': 0.98, 'max_grad_norm': 1, 'vf_coef': 0.13105756499231613, 'net_arch': 'small', 'activation_fn': 'relu'}. Best is trial 8 with value: -187.4.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 19:38:17,951]\u001b[0m Trial 9 finished with value: -197.4 and parameters: {'batch_size': 64, 'n_steps': 256, 'gamma': 0.99, 'learning_rate': 0.008470268646324676, 'ent_coef': 2.7685658442854515e-07, 'clip_range': 0.2, 'n_epochs': 1, 'gae_lambda': 0.95, 'max_grad_norm': 1, 'vf_coef': 0.4648907786213886, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 8 with value: -187.4.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 19:38:25,018]\u001b[0m Trial 10 finished with value: -200.0 and parameters: {'batch_size': 32, 'n_steps': 16, 'gamma': 0.9, 'learning_rate': 0.016851352274006866, 'ent_coef': 9.172549964912705e-06, 'clip_range': 0.1, 'n_epochs': 20, 'gae_lambda': 0.95, 'max_grad_norm': 0.7, 'vf_coef': 0.3170005582773894, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 8 with value: -187.4.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 19:38:27,622]\u001b[0m Trial 11 finished with value: -200.0 and parameters: {'batch_size': 128, 'n_steps': 32, 'gamma': 0.995, 'learning_rate': 4.3838724051028805e-05, 'ent_coef': 0.00015088510827427612, 'clip_range': 0.3, 'n_epochs': 5, 'gae_lambda': 0.98, 'max_grad_norm': 1, 'vf_coef': 0.4218567289368417, 'net_arch': 'small', 'activation_fn': 'relu'}. Best is trial 8 with value: -187.4.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 19:38:44,030]\u001b[0m Trial 12 finished with value: -200.0 and parameters: {'batch_size': 64, 'n_steps': 256, 'gamma': 0.995, 'learning_rate': 0.0009017780129082546, 'ent_coef': 4.661452641770679e-08, 'clip_range': 0.1, 'n_epochs': 1, 'gae_lambda': 0.95, 'max_grad_norm': 2, 'vf_coef': 0.33868029270905586, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 8 with value: -187.4.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 19:39:17,383]\u001b[0m Trial 13 finished with value: -200.0 and parameters: {'batch_size': 512, 'n_steps': 512, 'gamma': 0.99, 'learning_rate': 0.33796930562797206, 'ent_coef': 5.031018696893607e-06, 'clip_range': 0.2, 'n_epochs': 1, 'gae_lambda': 0.95, 'max_grad_norm': 1, 'vf_coef': 0.8601208613286164, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 8 with value: -187.4.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 19:39:21,499]\u001b[0m Trial 14 finished with value: -200.0 and parameters: {'batch_size': 64, 'n_steps': 64, 'gamma': 0.99, 'learning_rate': 0.006116631074528813, 'ent_coef': 5.4943633659104706e-05, 'clip_range': 0.2, 'n_epochs': 1, 'gae_lambda': 0.9, 'max_grad_norm': 1, 'vf_coef': 0.16275539621051793, 'net_arch': 'small', 'activation_fn': 'relu'}. Best is trial 8 with value: -187.4.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 19:39:25,514]\u001b[0m Trial 15 finished with value: -200.0 and parameters: {'batch_size': 16, 'n_steps': 32, 'gamma': 0.99, 'learning_rate': 0.0007720562804906679, 'ent_coef': 0.0005725065232277429, 'clip_range': 0.2, 'n_epochs': 5, 'gae_lambda': 0.98, 'max_grad_norm': 0.9, 'vf_coef': 0.21730126671494102, 'net_arch': 'small', 'activation_fn': 'relu'}. Best is trial 8 with value: -187.4.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 19:39:27,874]\u001b[0m Trial 16 finished with value: -200.0 and parameters: {'batch_size': 64, 'n_steps': 8, 'gamma': 0.9999, 'learning_rate': 0.001739543673045343, 'ent_coef': 3.1345039711869626e-07, 'clip_range': 0.2, 'n_epochs': 1, 'gae_lambda': 0.95, 'max_grad_norm': 1, 'vf_coef': 0.38852695681086036, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 8 with value: -187.4.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 19:41:02,706]\u001b[0m Trial 0 finished with value: -200.0 and parameters: {'batch_size': 16, 'n_steps': 2048, 'gamma': 0.99, 'learning_rate': 0.12127914754400428, 'ent_coef': 0.004440910824003763, 'clip_range': 0.4, 'n_epochs': 10, 'gae_lambda': 0.92, 'max_grad_norm': 0.7, 'vf_coef': 0.28689549881845366, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 8 with value: -187.4.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 19:42:16,620]\u001b[0m Trial 18 finished with value: -200.0 and parameters: {'batch_size': 512, 'n_steps': 1024, 'gamma': 0.99, 'learning_rate': 0.12542427104502016, 'ent_coef': 1.0485071831699175e-05, 'clip_range': 0.3, 'n_epochs': 5, 'gae_lambda': 0.98, 'max_grad_norm': 1, 'vf_coef': 0.10380096204265721, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 8 with value: -187.4.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 19:42:32,634]\u001b[0m Trial 19 finished with value: -200.0 and parameters: {'batch_size': 256, 'n_steps': 256, 'gamma': 0.99, 'learning_rate': 0.0008646483665839992, 'ent_coef': 2.45422387381164e-08, 'clip_range': 0.2, 'n_epochs': 1, 'gae_lambda': 0.9, 'max_grad_norm': 1, 'vf_coef': 0.6433961038489, 'net_arch': 'small', 'activation_fn': 'relu'}. Best is trial 8 with value: -187.4.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 19:42:47,804]\u001b[0m Trial 20 finished with value: -149.0 and parameters: {'batch_size': 64, 'n_steps': 256, 'gamma': 0.98, 'learning_rate': 0.11636693240471037, 'ent_coef': 1.6285108993803506e-06, 'clip_range': 0.2, 'n_epochs': 5, 'gae_lambda': 0.99, 'max_grad_norm': 1, 'vf_coef': 0.6294764044804921, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 20 with value: -149.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 19:43:08,937]\u001b[0m Trial 21 finished with value: -200.0 and parameters: {'batch_size': 32, 'n_steps': 256, 'gamma': 0.98, 'learning_rate': 0.06411506162517407, 'ent_coef': 3.4057946827857794e-07, 'clip_range': 0.2, 'n_epochs': 5, 'gae_lambda': 0.99, 'max_grad_norm': 1, 'vf_coef': 0.4068870250687954, 'net_arch': 'medium', 'activation_fn': 'tanh'}. Best is trial 20 with value: -149.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 19:43:27,076]\u001b[0m Trial 22 finished with value: -200.0 and parameters: {'batch_size': 8, 'n_steps': 128, 'gamma': 0.99, 'learning_rate': 0.000298800151740121, 'ent_coef': 0.005789364335266225, 'clip_range': 0.3, 'n_epochs': 5, 'gae_lambda': 1.0, 'max_grad_norm': 1, 'vf_coef': 0.047938282599125706, 'net_arch': 'small', 'activation_fn': 'relu'}. Best is trial 20 with value: -149.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 19:43:28,546]\u001b[0m Trial 17 finished with value: -200.0 and parameters: {'batch_size': 16, 'n_steps': 2048, 'gamma': 0.999, 'learning_rate': 0.0009888116406324987, 'ent_coef': 1.5307668423562696e-05, 'clip_range': 0.3, 'n_epochs': 5, 'gae_lambda': 1.0, 'max_grad_norm': 1, 'vf_coef': 0.035396917057286315, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 20 with value: -149.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 19:43:29,359]\u001b[0m Trial 23 finished with value: -200.0 and parameters: {'batch_size': 16, 'n_steps': 32, 'gamma': 0.99, 'learning_rate': 2.4283762796713453e-05, 'ent_coef': 3.230527339972465e-07, 'clip_range': 0.3, 'n_epochs': 1, 'gae_lambda': 0.98, 'max_grad_norm': 0.5, 'vf_coef': 0.1996857472046977, 'net_arch': 'small', 'activation_fn': 'relu'}. Best is trial 20 with value: -149.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 19:43:35,187]\u001b[0m Trial 24 finished with value: -200.0 and parameters: {'batch_size': 64, 'n_steps': 8, 'gamma': 0.999, 'learning_rate': 0.023224078009260078, 'ent_coef': 8.219006042035764e-07, 'clip_range': 0.2, 'n_epochs': 5, 'gae_lambda': 1.0, 'max_grad_norm': 1, 'vf_coef': 0.7813200401431895, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 20 with value: -149.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 19:43:51,593]\u001b[0m Trial 26 finished with value: -200.0 and parameters: {'batch_size': 64, 'n_steps': 128, 'gamma': 0.98, 'learning_rate': 0.07360875805324484, 'ent_coef': 5.948278147310802e-06, 'clip_range': 0.2, 'n_epochs': 20, 'gae_lambda': 0.99, 'max_grad_norm': 0.9, 'vf_coef': 0.45309741861071884, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 20 with value: -149.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 19:43:55,109]\u001b[0m Trial 27 finished with value: -200.0 and parameters: {'batch_size': 16, 'n_steps': 32, 'gamma': 0.98, 'learning_rate': 3.406845082795273e-05, 'ent_coef': 0.014736313394470563, 'clip_range': 0.3, 'n_epochs': 5, 'gae_lambda': 0.92, 'max_grad_norm': 0.7, 'vf_coef': 0.1661567656330835, 'net_arch': 'medium', 'activation_fn': 'relu'}. Best is trial 20 with value: -149.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 19:44:00,438]\u001b[0m Trial 25 finished with value: -200.0 and parameters: {'batch_size': 64, 'n_steps': 256, 'gamma': 0.98, 'learning_rate': 0.004540430407347214, 'ent_coef': 2.0382307263051183e-05, 'clip_range': 0.4, 'n_epochs': 20, 'gae_lambda': 0.98, 'max_grad_norm': 1, 'vf_coef': 0.7925615466791361, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 20 with value: -149.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 19:44:21,124]\u001b[0m Trial 29 finished with value: -200.0 and parameters: {'batch_size': 512, 'n_steps': 256, 'gamma': 0.9, 'learning_rate': 0.08331911776986427, 'ent_coef': 2.0335537965205082e-05, 'clip_range': 0.2, 'n_epochs': 5, 'gae_lambda': 0.99, 'max_grad_norm': 0.6, 'vf_coef': 0.7769358828465835, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 20 with value: -149.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 19:44:40,299]\u001b[0m Trial 30 finished with value: -200.0 and parameters: {'batch_size': 256, 'n_steps': 256, 'gamma': 0.98, 'learning_rate': 0.7426180361948673, 'ent_coef': 5.7440299455589576e-05, 'clip_range': 0.4, 'n_epochs': 5, 'gae_lambda': 0.99, 'max_grad_norm': 1, 'vf_coef': 0.6913382015949942, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 20 with value: -149.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 19:44:59,288]\u001b[0m Trial 31 finished with value: -200.0 and parameters: {'batch_size': 128, 'n_steps': 256, 'gamma': 0.99, 'learning_rate': 0.0012057631098794052, 'ent_coef': 1.271847404348723e-07, 'clip_range': 0.2, 'n_epochs': 10, 'gae_lambda': 0.95, 'max_grad_norm': 1, 'vf_coef': 0.31047909346315683, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 20 with value: -149.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 19:45:06,712]\u001b[0m Trial 28 finished with value: -200.0 and parameters: {'batch_size': 16, 'n_steps': 512, 'gamma': 0.95, 'learning_rate': 9.948475920316534e-05, 'ent_coef': 0.009791122820586183, 'clip_range': 0.4, 'n_epochs': 5, 'gae_lambda': 0.98, 'max_grad_norm': 1, 'vf_coef': 0.04398592906771334, 'net_arch': 'small', 'activation_fn': 'relu'}. Best is trial 20 with value: -149.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 19:47:55,686]\u001b[0m Trial 32 finished with value: -200.0 and parameters: {'batch_size': 16, 'n_steps': 1024, 'gamma': 0.999, 'learning_rate': 0.042079836752547076, 'ent_coef': 0.008254498451097568, 'clip_range': 0.4, 'n_epochs': 10, 'gae_lambda': 0.92, 'max_grad_norm': 0.6, 'vf_coef': 0.2670995199064061, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 20 with value: -149.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 19:50:46,895]\u001b[0m Trial 33 finished with value: -200.0 and parameters: {'batch_size': 16, 'n_steps': 2048, 'gamma': 0.9999, 'learning_rate': 0.17513786878944457, 'ent_coef': 0.0007487640759966331, 'clip_range': 0.4, 'n_epochs': 10, 'gae_lambda': 0.95, 'max_grad_norm': 0.7, 'vf_coef': 0.1705711666897204, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 20 with value: -149.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 19:53:17,454]\u001b[0m Trial 34 finished with value: -200.0 and parameters: {'batch_size': 16, 'n_steps': 2048, 'gamma': 0.99, 'learning_rate': 0.021600486145795218, 'ent_coef': 0.0040070425588517545, 'clip_range': 0.2, 'n_epochs': 10, 'gae_lambda': 0.92, 'max_grad_norm': 0.7, 'vf_coef': 0.23669350798287891, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 20 with value: -149.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 19:53:19,938]\u001b[0m Trial 36 finished with value: -200.0 and parameters: {'batch_size': 8, 'n_steps': 16, 'gamma': 0.99, 'learning_rate': 0.02018226713278791, 'ent_coef': 4.171032997477284e-08, 'clip_range': 0.2, 'n_epochs': 1, 'gae_lambda': 0.95, 'max_grad_norm': 0.3, 'vf_coef': 0.5124021822568026, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 20 with value: -149.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 19:54:11,617]\u001b[0m Trial 37 finished with value: -162.2 and parameters: {'batch_size': 256, 'n_steps': 1024, 'gamma': 0.99, 'learning_rate': 0.0002521670207985891, 'ent_coef': 0.0006013159367306166, 'clip_range': 0.3, 'n_epochs': 5, 'gae_lambda': 0.98, 'max_grad_norm': 5, 'vf_coef': 0.006860680790170409, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 20 with value: -149.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 19:55:24,461]\u001b[0m Trial 38 finished with value: -200.0 and parameters: {'batch_size': 64, 'n_steps': 1024, 'gamma': 0.9999, 'learning_rate': 0.0017106989933227004, 'ent_coef': 0.0011756209623635674, 'clip_range': 0.3, 'n_epochs': 5, 'gae_lambda': 0.98, 'max_grad_norm': 5, 'vf_coef': 0.27269403356955135, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 20 with value: -149.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 19:57:59,634]\u001b[0m Trial 39 finished with value: -191.8 and parameters: {'batch_size': 8, 'n_steps': 1024, 'gamma': 0.995, 'learning_rate': 0.0001090640311095499, 'ent_coef': 0.00045068314052052003, 'clip_range': 0.3, 'n_epochs': 5, 'gae_lambda': 0.98, 'max_grad_norm': 5, 'vf_coef': 9.918403789646417e-05, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 20 with value: -149.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 19:59:30,646]\u001b[0m Trial 35 finished with value: -200.0 and parameters: {'batch_size': 8, 'n_steps': 2048, 'gamma': 0.99, 'learning_rate': 0.006159958043683809, 'ent_coef': 0.006152606227638656, 'clip_range': 0.1, 'n_epochs': 10, 'gae_lambda': 0.9, 'max_grad_norm': 0.7, 'vf_coef': 0.18261343502376784, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 20 with value: -149.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 20:00:34,130]\u001b[0m Trial 41 finished with value: -200.0 and parameters: {'batch_size': 256, 'n_steps': 1024, 'gamma': 0.99, 'learning_rate': 0.0008079967539133763, 'ent_coef': 4.914283720340858e-05, 'clip_range': 0.3, 'n_epochs': 1, 'gae_lambda': 0.98, 'max_grad_norm': 5, 'vf_coef': 0.026644160222924523, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 20 with value: -149.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 20:02:00,584]\u001b[0m Trial 42 finished with value: -200.0 and parameters: {'batch_size': 8, 'n_steps': 1024, 'gamma': 0.995, 'learning_rate': 0.0002880055439576846, 'ent_coef': 0.0008475674428323561, 'clip_range': 0.3, 'n_epochs': 1, 'gae_lambda': 0.98, 'max_grad_norm': 0.7, 'vf_coef': 0.016777267240431097, 'net_arch': 'medium', 'activation_fn': 'tanh'}. Best is trial 20 with value: -149.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 20:04:39,621]\u001b[0m Trial 43 finished with value: -200.0 and parameters: {'batch_size': 8, 'n_steps': 1024, 'gamma': 0.98, 'learning_rate': 3.076504219724907e-05, 'ent_coef': 0.0004319042662809333, 'clip_range': 0.1, 'n_epochs': 5, 'gae_lambda': 0.98, 'max_grad_norm': 5, 'vf_coef': 0.1912234144339803, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 20 with value: -149.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 20:04:59,495]\u001b[0m Trial 44 finished with value: -200.0 and parameters: {'batch_size': 8, 'n_steps': 128, 'gamma': 0.995, 'learning_rate': 0.0004143103195567119, 'ent_coef': 0.001461365557359884, 'clip_range': 0.4, 'n_epochs': 5, 'gae_lambda': 0.98, 'max_grad_norm': 2, 'vf_coef': 0.3221803946877785, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 20 with value: -149.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 20:05:03,892]\u001b[0m Trial 45 finished with value: -200.0 and parameters: {'batch_size': 8, 'n_steps': 16, 'gamma': 0.99, 'learning_rate': 0.0001733481084470107, 'ent_coef': 0.0002148156225876836, 'clip_range': 0.3, 'n_epochs': 5, 'gae_lambda': 1.0, 'max_grad_norm': 5, 'vf_coef': 0.040660984213401814, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 20 with value: -149.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 20:05:06,955]\u001b[0m Trial 46 finished with value: -200.0 and parameters: {'batch_size': 256, 'n_steps': 32, 'gamma': 0.99, 'learning_rate': 5.273764192216495e-05, 'ent_coef': 0.0003488149311129291, 'clip_range': 0.3, 'n_epochs': 5, 'gae_lambda': 0.98, 'max_grad_norm': 1, 'vf_coef': 0.154427005433752, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 20 with value: -149.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 20:05:11,879]\u001b[0m Trial 47 finished with value: -200.0 and parameters: {'batch_size': 32, 'n_steps': 8, 'gamma': 0.995, 'learning_rate': 6.243116273206849e-05, 'ent_coef': 0.0001207100071831004, 'clip_range': 0.3, 'n_epochs': 5, 'gae_lambda': 0.98, 'max_grad_norm': 5, 'vf_coef': 0.07880140764338645, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 20 with value: -149.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 20:05:30,708]\u001b[0m Trial 48 finished with value: -200.0 and parameters: {'batch_size': 64, 'n_steps': 256, 'gamma': 0.98, 'learning_rate': 0.057684050911825276, 'ent_coef': 7.02298418311887e-07, 'clip_range': 0.1, 'n_epochs': 5, 'gae_lambda': 0.8, 'max_grad_norm': 1, 'vf_coef': 0.5267968426833846, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 20 with value: -149.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 20:05:47,542]\u001b[0m Trial 49 finished with value: -200.0 and parameters: {'batch_size': 64, 'n_steps': 256, 'gamma': 0.9, 'learning_rate': 0.02203680369345206, 'ent_coef': 4.876478202887214e-07, 'clip_range': 0.2, 'n_epochs': 1, 'gae_lambda': 0.92, 'max_grad_norm': 0.5, 'vf_coef': 0.3734767475492564, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 20 with value: -149.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 20:05:52,410]\u001b[0m Trial 50 finished with value: -200.0 and parameters: {'batch_size': 16, 'n_steps': 16, 'gamma': 0.99, 'learning_rate': 3.8272547854542814e-05, 'ent_coef': 0.0018937949939101945, 'clip_range': 0.3, 'n_epochs': 10, 'gae_lambda': 0.8, 'max_grad_norm': 1, 'vf_coef': 0.24462744011419837, 'net_arch': 'small', 'activation_fn': 'relu'}. Best is trial 20 with value: -149.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 20:05:57,475]\u001b[0m Trial 51 finished with value: -200.0 and parameters: {'batch_size': 256, 'n_steps': 64, 'gamma': 0.9999, 'learning_rate': 9.329351079864493e-05, 'ent_coef': 0.003883275422064456, 'clip_range': 0.2, 'n_epochs': 5, 'gae_lambda': 0.95, 'max_grad_norm': 5, 'vf_coef': 0.01302868812141516, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 20 with value: -149.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 20:06:14,211]\u001b[0m Trial 52 finished with value: -200.0 and parameters: {'batch_size': 64, 'n_steps': 256, 'gamma': 0.99, 'learning_rate': 0.005197316334900295, 'ent_coef': 2.49078456682768e-07, 'clip_range': 0.2, 'n_epochs': 1, 'gae_lambda': 0.8, 'max_grad_norm': 1, 'vf_coef': 0.5114263085607632, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 20 with value: -149.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 20:06:17,851]\u001b[0m Trial 40 finished with value: -200.0 and parameters: {'batch_size': 8, 'n_steps': 1024, 'gamma': 0.995, 'learning_rate': 4.544045961712822e-05, 'ent_coef': 0.0001037735212441533, 'clip_range': 0.3, 'n_epochs': 20, 'gae_lambda': 0.98, 'max_grad_norm': 0.7, 'vf_coef': 0.047107053229890214, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 20 with value: -149.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 20:07:49,412]\u001b[0m Trial 53 finished with value: -200.0 and parameters: {'batch_size': 64, 'n_steps': 1024, 'gamma': 0.9, 'learning_rate': 0.1267877977902437, 'ent_coef': 3.42097224505666e-07, 'clip_range': 0.3, 'n_epochs': 5, 'gae_lambda': 0.99, 'max_grad_norm': 0.3, 'vf_coef': 0.6714149589543749, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 20 with value: -149.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 20:07:54,418]\u001b[0m Trial 55 finished with value: -200.0 and parameters: {'batch_size': 256, 'n_steps': 16, 'gamma': 0.99, 'learning_rate': 0.30614565711137054, 'ent_coef': 0.00044789652382420383, 'clip_range': 0.4, 'n_epochs': 10, 'gae_lambda': 0.8, 'max_grad_norm': 0.7, 'vf_coef': 0.3724653798598616, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 20 with value: -149.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 20:09:29,332]\u001b[0m Trial 54 finished with value: -200.0 and parameters: {'batch_size': 8, 'n_steps': 1024, 'gamma': 0.9, 'learning_rate': 1.1182420216303895e-05, 'ent_coef': 0.0065067151189728105, 'clip_range': 0.3, 'n_epochs': 5, 'gae_lambda': 1.0, 'max_grad_norm': 0.6, 'vf_coef': 0.12766827875518102, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 20 with value: -149.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 20:10:41,429]\u001b[0m Trial 57 finished with value: -200.0 and parameters: {'batch_size': 128, 'n_steps': 1024, 'gamma': 0.98, 'learning_rate': 0.0020301222257976042, 'ent_coef': 0.0003578595235703666, 'clip_range': 0.3, 'n_epochs': 5, 'gae_lambda': 0.8, 'max_grad_norm': 5, 'vf_coef': 0.007047106705902549, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 20 with value: -149.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 20:11:01,464]\u001b[0m Trial 56 finished with value: -200.0 and parameters: {'batch_size': 8, 'n_steps': 1024, 'gamma': 0.995, 'learning_rate': 3.926207303474941e-05, 'ent_coef': 1.6538212029056157e-05, 'clip_range': 0.3, 'n_epochs': 5, 'gae_lambda': 0.95, 'max_grad_norm': 5, 'vf_coef': 0.008744891225739978, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 20 with value: -149.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 20:11:08,288]\u001b[0m Trial 59 finished with value: -195.0 and parameters: {'batch_size': 8, 'n_steps': 32, 'gamma': 0.98, 'learning_rate': 0.03412462463398087, 'ent_coef': 1.8316593250613078e-07, 'clip_range': 0.2, 'n_epochs': 5, 'gae_lambda': 0.99, 'max_grad_norm': 1, 'vf_coef': 0.8296333014894198, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 20 with value: -149.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 20:11:20,806]\u001b[0m Trial 60 finished with value: -183.2 and parameters: {'batch_size': 8, 'n_steps': 64, 'gamma': 0.98, 'learning_rate': 0.0573999830381167, 'ent_coef': 1.3961022230285814e-07, 'clip_range': 0.2, 'n_epochs': 5, 'gae_lambda': 0.99, 'max_grad_norm': 1, 'vf_coef': 0.978383779600865, 'net_arch': 'medium', 'activation_fn': 'tanh'}. Best is trial 20 with value: -149.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 20:11:41,608]\u001b[0m Trial 61 finished with value: -200.0 and parameters: {'batch_size': 8, 'n_steps': 64, 'gamma': 0.99, 'learning_rate': 0.05166863118341793, 'ent_coef': 7.911762726538054e-08, 'clip_range': 0.2, 'n_epochs': 10, 'gae_lambda': 0.99, 'max_grad_norm': 2, 'vf_coef': 0.8883458534449838, 'net_arch': 'medium', 'activation_fn': 'tanh'}. Best is trial 20 with value: -149.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 20:11:47,157]\u001b[0m Trial 62 finished with value: -156.0 and parameters: {'batch_size': 8, 'n_steps': 8, 'gamma': 0.98, 'learning_rate': 0.023100859139079725, 'ent_coef': 1.7357460056306985e-06, 'clip_range': 0.2, 'n_epochs': 5, 'gae_lambda': 0.99, 'max_grad_norm': 0.3, 'vf_coef': 0.7273629028636981, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 20 with value: -149.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 20:11:53,229]\u001b[0m Trial 63 finished with value: -200.0 and parameters: {'batch_size': 256, 'n_steps': 64, 'gamma': 0.98, 'learning_rate': 0.6374686855581099, 'ent_coef': 2.423468878631095e-07, 'clip_range': 0.2, 'n_epochs': 5, 'gae_lambda': 0.8, 'max_grad_norm': 1, 'vf_coef': 0.9701707070688317, 'net_arch': 'medium', 'activation_fn': 'tanh'}. Best is trial 20 with value: -149.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 20:12:07,104]\u001b[0m Trial 64 finished with value: -200.0 and parameters: {'batch_size': 8, 'n_steps': 64, 'gamma': 0.98, 'learning_rate': 0.0025097012840925924, 'ent_coef': 5.946070642668037e-07, 'clip_range': 0.2, 'n_epochs': 5, 'gae_lambda': 0.99, 'max_grad_norm': 1, 'vf_coef': 0.7317985976138062, 'net_arch': 'medium', 'activation_fn': 'tanh'}. Best is trial 20 with value: -149.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 20:12:13,557]\u001b[0m Trial 65 finished with value: -200.0 and parameters: {'batch_size': 8, 'n_steps': 8, 'gamma': 0.98, 'learning_rate': 0.009000200074006655, 'ent_coef': 7.013141086105775e-06, 'clip_range': 0.2, 'n_epochs': 5, 'gae_lambda': 0.99, 'max_grad_norm': 0.3, 'vf_coef': 0.7154119623340225, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 20 with value: -149.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 20:12:18,041]\u001b[0m Trial 66 finished with value: -200.0 and parameters: {'batch_size': 16, 'n_steps': 32, 'gamma': 0.9999, 'learning_rate': 3.919473982396777e-05, 'ent_coef': 1.906256773062211e-05, 'clip_range': 0.3, 'n_epochs': 5, 'gae_lambda': 0.98, 'max_grad_norm': 0.7, 'vf_coef': 0.1419055974519257, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 20 with value: -149.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 20:12:24,817]\u001b[0m Trial 67 finished with value: -200.0 and parameters: {'batch_size': 8, 'n_steps': 32, 'gamma': 0.98, 'learning_rate': 0.8275324823243991, 'ent_coef': 2.7797196028538244e-08, 'clip_range': 0.2, 'n_epochs': 5, 'gae_lambda': 0.99, 'max_grad_norm': 1, 'vf_coef': 0.6621406412251228, 'net_arch': 'small', 'activation_fn': 'relu'}. Best is trial 20 with value: -149.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 20:12:31,845]\u001b[0m Trial 68 finished with value: -200.0 and parameters: {'batch_size': 8, 'n_steps': 32, 'gamma': 0.9, 'learning_rate': 0.003921230288808527, 'ent_coef': 2.1871046289223403e-07, 'clip_range': 0.2, 'n_epochs': 5, 'gae_lambda': 0.99, 'max_grad_norm': 0.7, 'vf_coef': 0.7183593352002648, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 20 with value: -149.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 20:13:00,814]\u001b[0m Trial 69 finished with value: -200.0 and parameters: {'batch_size': 64, 'n_steps': 256, 'gamma': 0.9999, 'learning_rate': 0.6116628759000865, 'ent_coef': 1.3369115744118875e-07, 'clip_range': 0.2, 'n_epochs': 10, 'gae_lambda': 0.99, 'max_grad_norm': 0.7, 'vf_coef': 0.7118220235756538, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 20 with value: -149.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 20:13:04,594]\u001b[0m Trial 70 finished with value: -200.0 and parameters: {'batch_size': 512, 'n_steps': 32, 'gamma': 0.98, 'learning_rate': 0.008462330177943133, 'ent_coef': 1.7951168518430322e-07, 'clip_range': 0.2, 'n_epochs': 5, 'gae_lambda': 0.92, 'max_grad_norm': 0.9, 'vf_coef': 0.6614699769510549, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 20 with value: -149.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 20:13:12,749]\u001b[0m Trial 71 finished with value: -200.0 and parameters: {'batch_size': 16, 'n_steps': 32, 'gamma': 0.99, 'learning_rate': 0.00010569141327859447, 'ent_coef': 0.0005470188874425472, 'clip_range': 0.3, 'n_epochs': 20, 'gae_lambda': 0.98, 'max_grad_norm': 1, 'vf_coef': 0.41690937733202493, 'net_arch': 'medium', 'activation_fn': 'relu'}. Best is trial 20 with value: -149.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 20:13:49,244]\u001b[0m Trial 72 finished with value: -200.0 and parameters: {'batch_size': 8, 'n_steps': 256, 'gamma': 0.98, 'learning_rate': 0.10700620574786378, 'ent_coef': 3.5221468885052966e-08, 'clip_range': 0.2, 'n_epochs': 5, 'gae_lambda': 0.9, 'max_grad_norm': 1, 'vf_coef': 0.9604394012110464, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 20 with value: -149.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 20:13:53,316]\u001b[0m Trial 73 finished with value: -200.0 and parameters: {'batch_size': 16, 'n_steps': 32, 'gamma': 0.99, 'learning_rate': 2.3567506251913505e-05, 'ent_coef': 0.0005100284093245124, 'clip_range': 0.3, 'n_epochs': 5, 'gae_lambda': 0.92, 'max_grad_norm': 1, 'vf_coef': 0.21761232503367017, 'net_arch': 'small', 'activation_fn': 'relu'}. Best is trial 20 with value: -149.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 20:13:57,971]\u001b[0m Trial 74 finished with value: -200.0 and parameters: {'batch_size': 64, 'n_steps': 64, 'gamma': 0.99, 'learning_rate': 0.06349498329659885, 'ent_coef': 1.7450197996022774e-06, 'clip_range': 0.2, 'n_epochs': 5, 'gae_lambda': 0.99, 'max_grad_norm': 1, 'vf_coef': 0.5957703271552405, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 20 with value: -149.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 20:14:01,011]\u001b[0m Trial 75 finished with value: -189.4 and parameters: {'batch_size': 512, 'n_steps': 16, 'gamma': 0.99, 'learning_rate': 0.002418186908238383, 'ent_coef': 0.0034272417168782826, 'clip_range': 0.3, 'n_epochs': 5, 'gae_lambda': 0.98, 'max_grad_norm': 1, 'vf_coef': 0.07506727270386813, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 20 with value: -149.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 20:14:04,612]\u001b[0m Trial 76 finished with value: -200.0 and parameters: {'batch_size': 512, 'n_steps': 16, 'gamma': 0.98, 'learning_rate': 0.0011877297851056903, 'ent_coef': 0.043165625286406, 'clip_range': 0.3, 'n_epochs': 5, 'gae_lambda': 0.98, 'max_grad_norm': 1, 'vf_coef': 0.08302685231428937, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 20 with value: -149.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 20:14:07,191]\u001b[0m Trial 77 finished with value: -200.0 and parameters: {'batch_size': 8, 'n_steps': 8, 'gamma': 0.98, 'learning_rate': 0.42878861742473934, 'ent_coef': 1.6145467081549437e-08, 'clip_range': 0.4, 'n_epochs': 1, 'gae_lambda': 0.99, 'max_grad_norm': 1, 'vf_coef': 0.964670022199706, 'net_arch': 'medium', 'activation_fn': 'tanh'}. Best is trial 20 with value: -149.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 20:14:11,453]\u001b[0m Trial 78 finished with value: -200.0 and parameters: {'batch_size': 512, 'n_steps': 64, 'gamma': 0.99, 'learning_rate': 0.0011270792647248757, 'ent_coef': 0.0032891580641166065, 'clip_range': 0.1, 'n_epochs': 5, 'gae_lambda': 0.98, 'max_grad_norm': 0.6, 'vf_coef': 0.17564462284279736, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 20 with value: -149.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 20:14:15,687]\u001b[0m Trial 79 finished with value: -200.0 and parameters: {'batch_size': 512, 'n_steps': 16, 'gamma': 0.99, 'learning_rate': 0.05071625763775532, 'ent_coef': 0.0004887747497894036, 'clip_range': 0.3, 'n_epochs': 5, 'gae_lambda': 0.8, 'max_grad_norm': 0.6, 'vf_coef': 0.07272785475498493, 'net_arch': 'medium', 'activation_fn': 'relu'}. Best is trial 20 with value: -149.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 20:14:34,453]\u001b[0m Trial 80 finished with value: -200.0 and parameters: {'batch_size': 64, 'n_steps': 256, 'gamma': 0.98, 'learning_rate': 0.0560168582125918, 'ent_coef': 1.5381038232539463e-05, 'clip_range': 0.2, 'n_epochs': 5, 'gae_lambda': 0.99, 'max_grad_norm': 0.3, 'vf_coef': 0.6129962997077183, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 20 with value: -149.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 20:14:53,831]\u001b[0m Trial 58 finished with value: -200.0 and parameters: {'batch_size': 16, 'n_steps': 2048, 'gamma': 0.99, 'learning_rate': 1.6024075515871653e-05, 'ent_coef': 0.0002100072908661281, 'clip_range': 0.3, 'n_epochs': 5, 'gae_lambda': 0.98, 'max_grad_norm': 2, 'vf_coef': 0.06752190420313808, 'net_arch': 'small', 'activation_fn': 'relu'}. Best is trial 20 with value: -149.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 20:15:15,085]\u001b[0m Trial 81 finished with value: -200.0 and parameters: {'batch_size': 128, 'n_steps': 512, 'gamma': 0.99, 'learning_rate': 1.9443783531376716e-05, 'ent_coef': 0.003456132795401217, 'clip_range': 0.3, 'n_epochs': 5, 'gae_lambda': 0.98, 'max_grad_norm': 5, 'vf_coef': 0.018296587869717072, 'net_arch': 'small', 'activation_fn': 'relu'}. Best is trial 20 with value: -149.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 20:15:33,417]\u001b[0m Trial 82 finished with value: -200.0 and parameters: {'batch_size': 256, 'n_steps': 512, 'gamma': 0.99, 'learning_rate': 1.2885354780845714e-05, 'ent_coef': 0.004377940127612857, 'clip_range': 0.3, 'n_epochs': 5, 'gae_lambda': 0.98, 'max_grad_norm': 0.9, 'vf_coef': 0.04241295443567047, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 20 with value: -149.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 20:15:52,021]\u001b[0m Trial 84 finished with value: -200.0 and parameters: {'batch_size': 8, 'n_steps': 32, 'gamma': 0.98, 'learning_rate': 0.0018766999709881633, 'ent_coef': 2.427543666203054e-07, 'clip_range': 0.4, 'n_epochs': 20, 'gae_lambda': 0.99, 'max_grad_norm': 1, 'vf_coef': 0.8813874897778674, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 20 with value: -149.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 20:16:04,819]\u001b[0m Trial 85 finished with value: -200.0 and parameters: {'batch_size': 8, 'n_steps': 64, 'gamma': 0.98, 'learning_rate': 0.15620311293933745, 'ent_coef': 6.42124872380938e-08, 'clip_range': 0.3, 'n_epochs': 5, 'gae_lambda': 0.99, 'max_grad_norm': 5, 'vf_coef': 0.9622541806397485, 'net_arch': 'medium', 'activation_fn': 'relu'}. Best is trial 20 with value: -149.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 20:18:30,985]\u001b[0m Trial 86 finished with value: -200.0 and parameters: {'batch_size': 256, 'n_steps': 2048, 'gamma': 0.99, 'learning_rate': 0.00015201718519787484, 'ent_coef': 2.4331613591484954e-06, 'clip_range': 0.3, 'n_epochs': 5, 'gae_lambda': 0.8, 'max_grad_norm': 0.5, 'vf_coef': 0.13101469336333432, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 20 with value: -149.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 20:18:35,801]\u001b[0m Trial 83 finished with value: -186.8 and parameters: {'batch_size': 64, 'n_steps': 2048, 'gamma': 0.99, 'learning_rate': 0.02247477043466815, 'ent_coef': 0.026879274733605248, 'clip_range': 0.3, 'n_epochs': 10, 'gae_lambda': 0.98, 'max_grad_norm': 1, 'vf_coef': 0.15425546247958943, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 20 with value: -149.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 20:18:50,274]\u001b[0m Trial 87 finished with value: -200.0 and parameters: {'batch_size': 512, 'n_steps': 256, 'gamma': 0.98, 'learning_rate': 0.16058028843072802, 'ent_coef': 6.709920712730982e-07, 'clip_range': 0.2, 'n_epochs': 1, 'gae_lambda': 0.99, 'max_grad_norm': 1, 'vf_coef': 0.5475023178506582, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 20 with value: -149.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 20:21:58,750]\u001b[0m Trial 88 finished with value: -200.0 and parameters: {'batch_size': 64, 'n_steps': 2048, 'gamma': 0.99, 'learning_rate': 0.16330485541390374, 'ent_coef': 0.07460748224092116, 'clip_range': 0.3, 'n_epochs': 10, 'gae_lambda': 0.98, 'max_grad_norm': 1, 'vf_coef': 0.2169919545517907, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 20 with value: -149.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 20:23:04,034]\u001b[0m Trial 89 finished with value: -200.0 and parameters: {'batch_size': 64, 'n_steps': 2048, 'gamma': 0.99, 'learning_rate': 0.0031449398085186555, 'ent_coef': 0.0006817991668680439, 'clip_range': 0.1, 'n_epochs': 20, 'gae_lambda': 0.98, 'max_grad_norm': 1, 'vf_coef': 0.1967428560722563, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 20 with value: -149.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 20:23:15,415]\u001b[0m Trial 91 finished with value: -200.0 and parameters: {'batch_size': 8, 'n_steps': 16, 'gamma': 0.99, 'learning_rate': 0.01132084721297482, 'ent_coef': 0.018155246176651853, 'clip_range': 0.3, 'n_epochs': 10, 'gae_lambda': 0.98, 'max_grad_norm': 1, 'vf_coef': 0.18174675624501052, 'net_arch': 'medium', 'activation_fn': 'relu'}. Best is trial 20 with value: -149.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 20:23:33,691]\u001b[0m Trial 92 finished with value: -158.4 and parameters: {'batch_size': 64, 'n_steps': 256, 'gamma': 0.99, 'learning_rate': 0.02275813307899751, 'ent_coef': 4.352212009658255e-06, 'clip_range': 0.2, 'n_epochs': 1, 'gae_lambda': 0.95, 'max_grad_norm': 2, 'vf_coef': 0.5468006614763782, 'net_arch': 'small', 'activation_fn': 'relu'}. Best is trial 20 with value: -149.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 20:23:36,635]\u001b[0m Trial 93 finished with value: -200.0 and parameters: {'batch_size': 64, 'n_steps': 32, 'gamma': 0.99, 'learning_rate': 0.029355354370565065, 'ent_coef': 1.3941669892334132e-06, 'clip_range': 0.2, 'n_epochs': 1, 'gae_lambda': 0.99, 'max_grad_norm': 2, 'vf_coef': 0.7624408312588822, 'net_arch': 'small', 'activation_fn': 'relu'}. Best is trial 20 with value: -149.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 20:23:40,118]\u001b[0m Trial 94 finished with value: -200.0 and parameters: {'batch_size': 256, 'n_steps': 32, 'gamma': 0.99, 'learning_rate': 0.00018664576365711022, 'ent_coef': 0.0010253010525583322, 'clip_range': 0.2, 'n_epochs': 5, 'gae_lambda': 0.98, 'max_grad_norm': 5, 'vf_coef': 0.02199430792390697, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 20 with value: -149.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 20:24:18,052]\u001b[0m Trial 95 finished with value: -200.0 and parameters: {'batch_size': 64, 'n_steps': 512, 'gamma': 0.9, 'learning_rate': 0.12324992822862076, 'ent_coef': 1.7799738157762923e-07, 'clip_range': 0.2, 'n_epochs': 1, 'gae_lambda': 0.95, 'max_grad_norm': 2, 'vf_coef': 0.50505336759696, 'net_arch': 'small', 'activation_fn': 'relu'}. Best is trial 20 with value: -149.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 20:24:53,393]\u001b[0m Trial 96 finished with value: -162.4 and parameters: {'batch_size': 64, 'n_steps': 512, 'gamma': 0.95, 'learning_rate': 0.0008993194524623161, 'ent_coef': 0.04715149808681991, 'clip_range': 0.3, 'n_epochs': 10, 'gae_lambda': 0.98, 'max_grad_norm': 1, 'vf_coef': 0.4449412806736999, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 20 with value: -149.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 20:24:56,433]\u001b[0m Trial 97 finished with value: -200.0 and parameters: {'batch_size': 64, 'n_steps': 32, 'gamma': 0.95, 'learning_rate': 0.0009861439362697198, 'ent_coef': 0.01311819356863496, 'clip_range': 0.1, 'n_epochs': 10, 'gae_lambda': 0.98, 'max_grad_norm': 1, 'vf_coef': 0.483569226939453, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 20 with value: -149.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 20:25:37,951]\u001b[0m Trial 98 finished with value: -200.0 and parameters: {'batch_size': 64, 'n_steps': 512, 'gamma': 0.9999, 'learning_rate': 0.00668962268252919, 'ent_coef': 0.010128899071447853, 'clip_range': 0.3, 'n_epochs': 10, 'gae_lambda': 0.98, 'max_grad_norm': 2, 'vf_coef': 0.4909681463323067, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 20 with value: -149.0.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2024-01-24 20:26:23,571]\u001b[0m Trial 99 finished with value: -200.0 and parameters: {'batch_size': 64, 'n_steps': 512, 'gamma': 0.95, 'learning_rate': 0.00010828456366827538, 'ent_coef': 0.005285707620369715, 'clip_range': 0.3, 'n_epochs': 10, 'gae_lambda': 0.98, 'max_grad_norm': 0.5, 'vf_coef': 0.20423503889518801, 'net_arch': 'medium', 'activation_fn': 'relu'}. Best is trial 20 with value: -149.0.\u001b[0m\n",
            "\u001b[32m[I 2024-01-24 20:28:15,295]\u001b[0m Trial 90 finished with value: -189.0 and parameters: {'batch_size': 8, 'n_steps': 2048, 'gamma': 0.9999, 'learning_rate': 0.0024253227124096566, 'ent_coef': 0.014805234761433283, 'clip_range': 0.4, 'n_epochs': 10, 'gae_lambda': 0.98, 'max_grad_norm': 1, 'vf_coef': 0.16912436611461276, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 20 with value: -149.0.\u001b[0m\n",
            "Number of finished trials:  100\n",
            "Best trial:\n",
            "Value:  -149.0\n",
            "Params: \n",
            "    batch_size: 64\n",
            "    n_steps: 256\n",
            "    gamma: 0.98\n",
            "    learning_rate: 0.11636693240471037\n",
            "    ent_coef: 1.6285108993803506e-06\n",
            "    clip_range: 0.2\n",
            "    n_epochs: 5\n",
            "    gae_lambda: 0.99\n",
            "    max_grad_norm: 1\n",
            "    vf_coef: 0.6294764044804921\n",
            "    net_arch: small\n",
            "    activation_fn: tanh\n",
            "Writing report to logs/ppo/report_MountainCar-v0_100-trials-500-tpe-median_1706128095\n"
          ]
        }
      ],
      "source": [
        "!python -m rl_zoo3.train --algo ppo --env MountainCar-v0 -n 500 -optimize --n-trials 100 --n-jobs 2 --sampler tpe --pruner median"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVm9QPNVwKXN"
      },
      "source": [
        "### Record  a Video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "MPyfQxD5z26J"
      },
      "outputs": [],
      "source": [
        "# Set up display; otherwise rendering will fail\n",
        "import os\n",
        "os.system(\"Xvfb :1 -screen 0 1024x768x24 &\")\n",
        "os.environ['DISPLAY'] = ':1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ip3AauLzwNGP",
        "outputId": "fb237f49-e5b0-4c7e-88e0-3f0b725d0240"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-01-24 20:28:46.998161: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-01-24 20:28:46.998215: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-01-24 20:28:46.999558: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-01-24 20:28:47.007080: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-01-24 20:28:48.127486: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Loading latest experiment, id=1\n",
            "Loading logs/a2c/CartPole-v1_1/CartPole-v1.zip\n",
            "Loading logs/a2c/CartPole-v1_1/CartPole-v1.zip\n",
            "Saving video to /content/rl-baselines3-zoo/logs/a2c/CartPole-v1_1/videos/final-model-a2c-CartPole-v1-step-0-to-step-100.mp4\n",
            "Moviepy - Building video /content/rl-baselines3-zoo/logs/a2c/CartPole-v1_1/videos/final-model-a2c-CartPole-v1-step-0-to-step-100.mp4.\n",
            "Moviepy - Writing video /content/rl-baselines3-zoo/logs/a2c/CartPole-v1_1/videos/final-model-a2c-CartPole-v1-step-0-to-step-100.mp4\n",
            "\n",
            "Moviepy - Done !\n",
            "Moviepy - video ready /content/rl-baselines3-zoo/logs/a2c/CartPole-v1_1/videos/final-model-a2c-CartPole-v1-step-0-to-step-100.mp4\n"
          ]
        }
      ],
      "source": [
        "!python -m rl_zoo3.record_video --algo a2c --env CartPole-v1 --exp-id 0 -f logs/ -n 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBuUfnzI8DN6"
      },
      "source": [
        "### Display the video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ZC3OTfpf8CXu"
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "from pathlib import Path\n",
        "\n",
        "from IPython import display as ipythondisplay\n",
        "\n",
        "\n",
        "def show_videos(video_path=\"\", prefix=\"\"):\n",
        "    \"\"\"\n",
        "    Taken from https://github.com/eleurent/highway-env\n",
        "\n",
        "    :param video_path: (str) Path to the folder containing videos\n",
        "    :param prefix: (str) Filter the video, showing only the only starting with this prefix\n",
        "    \"\"\"\n",
        "    html = []\n",
        "    for mp4 in Path(video_path).glob(\"{}*.mp4\".format(prefix)):\n",
        "        video_b64 = base64.b64encode(mp4.read_bytes())\n",
        "        html.append(\n",
        "            \"\"\"<video alt=\"{}\" autoplay\n",
        "                    loop controls style=\"height: 400px;\">\n",
        "                    <source src=\"data:video/mp4;base64,{}\" type=\"video/mp4\" />\n",
        "                </video>\"\"\".format(\n",
        "                mp4, video_b64.decode(\"ascii\")\n",
        "            )\n",
        "        )\n",
        "    ipythondisplay.display(ipythondisplay.HTML(data=\"<br>\".join(html)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "oKOjFuwK9HI0",
        "outputId": "97b32d8c-1db4-4bf4-9e9c-a66af191b8f0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<video alt=\"logs/a2c/CartPole-v1_1/videos/final-model-a2c-CartPole-v1-step-0-to-step-100.mp4\" autoplay \n",
              "                    loop controls style=\"height: 400px;\">\n",
              "                    <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "                </video>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "show_videos(video_path='logs/a2c/CartPole-v1_1/videos/', prefix='')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class A2C(nn.Module):\n",
        "    def __init__(self, input_shape):\n",
        "        super().__init__()\n",
        "        self.policy = nn.Linear(in_features=input_shape, out_features=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.policy(x)"
      ],
      "metadata": {
        "id": "bIGN93dkpDyq"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjdpP0HE8D2p"
      },
      "source": [
        "### Continue Training\n",
        "\n",
        "Here, we will continue training of the previous model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zgMZQJJF6u1C"
      },
      "outputs": [],
      "source": [
        "!python -m rl_zoo3.train --algo a2c --env CartPole-v1 --n-timesteps 50000 -i logs/a2c/CartPole-v1_1/CartPole-v1.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GSaoyiAE8cVj"
      },
      "outputs": [],
      "source": [
        "!python -m rl_zoo3.enjoy --algo a2c --env CartPole-v1 --no-render --n-timesteps 1000 --folder logs/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jL9u4I1H-48O"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "rl-baselines-zoo.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}